# LÃ m cho AI Agent trá»Ÿ nÃªn Ä‘Ã¡ng tin cáº­y hÆ¡n nhá» Reinforcement Learning

* HÃ£y cháº¯c cháº¯n ráº±ng báº¡n Ä‘Ã£ Ä‘áº¡t hiá»‡u suáº¥t tá»‘i Ä‘a vá»›i `prompt-based`, cá»¥ thá»ƒ lÃ  context engineering
* Khi Ä‘Ã£ tá»‘i Æ°u prompt háº¿t má»©c vÃ  thá»±c sá»± cáº§n nÃ¢ng cao accuracy, tiáº¿t kiá»‡m chi phÃ­, giáº£m Ä‘á»™ trá»… => dÃ¹ng RL Ä‘á»ƒ huáº¥n luyá»‡n AI Agent
* => `lÃ  ná»n táº£ng Ä‘á»ƒ xÃ¢y dá»±ng há»‡ thá»‘ng agent hiá»‡u quáº£ vÃ  Ä‘Ã¡ng tin cáº­y`

**1. Táº§m quan trá»ng cá»§a AI Agent**

* AI agents Ä‘ang trá»Ÿ thÃ nh trá»¥ cá»™t trong tá»± Ä‘á»™ng hÃ³a vÃ  há»‡ thá»‘ng tá»± trá»‹.
* Viá»‡c xÃ¢y dá»±ng agent Ä‘Ã¡ng tin cáº­y lÃ  **thÃ¡ch thá»©c ká»¹ thuáº­t lá»›n**, nhÆ°ng cá»±c ká»³ quan trá»ng vÃ¬:

  * Trá»£ lÃ½ email sai â†’ máº¥t niá»m tin ngÆ°á»i dÃ¹ng.
  * PhÃ¢n tÃ­ch tÃ i chÃ­nh sai â†’ thiá»‡t háº¡i nghiÃªm trá»ng.
  * Há»‡ thá»‘ng cháº­m â†’ giáº£m nÄƒng suáº¥t.

**2. BÃ i há»c tá»« Kyle Corbitt táº¡i AI Engineer World's Fair**

* Nháº¥n máº¡nh cÃ¡ch lÃ m cho agent **Ä‘Ã¡ng tin cáº­y hÆ¡n báº±ng RL**
* ÄÆ°a ra chiáº¿n lÆ°á»£c vÆ°á»£t qua cÃ¡c khÃ³ khÄƒn trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n agent.

**3. Case study: Dá»± Ã¡n ARTÂ·E cá»§a OpenPipe**

* LÃ  má»™t **trá»£ lÃ½ email dÃ¹ng ngÃ´n ngá»¯ tá»± nhiÃªn** Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i.
* Agent dÃ¹ng 2 cÃ´ng cá»¥ chÃ­nh:

  * **Search Tool** â€“ tÃ¬m email chá»©a tá»« khÃ³a.
  * **Read Email Tool** â€“ Ä‘á»c ná»™i dung Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i.
* VÃ­ dá»¥: "Khi nÃ o Shari chuyá»ƒn Ä‘áº¿n Portland?" â†’ Agent tÃ¬m trong email vÃ  tráº£ lá»i chÃ­nh xÃ¡c.

**4. BÃ i há»c then chá»‘t:**

> "Äá»«ng báº¯t Ä‘áº§u báº±ng Reinforcement Learning!"

* Äá»™i ngÅ© ARTÂ·E **ban Ä‘áº§u khÃ´ng dÃ¹ng RL**, mÃ  tá»‘i Æ°u mÃ´ hÃ¬nh báº±ng prompt Ä‘á»ƒ Ä‘áº¡t hiá»‡u quáº£ cao nháº¥t trÆ°á»›c.
* Chá»‰ sau Ä‘Ã³ má»›i cÃ¢n nháº¯c Ä‘áº¿n RL náº¿u cáº§n tá»‘i Æ°u thÃªm.

#### âš ï¸ CÃ¢n nhÄƒc trÆ°á»›c khi traning vá»›i RL
1. **Cáº§n kiá»ƒm tra ká»¹ mÃ´i trÆ°á»ng trÆ°á»›c khi huáº¥n luyá»‡n RL**

   * Pháº£i Ä‘áº£m báº£o cÃ¡c **tool hoáº¡t Ä‘á»™ng Ä‘Ãºng**, truy cáº­p dá»¯ liá»‡u há»£p lá»‡.
   * Nhiá»u lá»—i phÃ¡t sinh tá»« pháº§n tÃ­ch há»£p ban Ä‘áº§u â€“ náº¿u debug trong giai Ä‘oáº¡n RL sáº½ **máº¥t thá»i gian, khÃ³ tÃ¬m lá»—i hÆ¡n**.

2. **Prompt tá»‘t cÃ³ thá»ƒ Ä‘Ã£ Ä‘á»§ dÃ¹ng**

   * CÃ³ nhiá»u trÆ°á»ng há»£p chá»‰ cáº§n tá»‘i Æ°u prompt lÃ  Ä‘Ã£ Ä‘áº¡t yÃªu cáº§u.
   * TrÃ¡nh Ä‘Æ°á»£c quy trÃ¬nh RL phá»©c táº¡p vÃ  tá»‘n kÃ©m náº¿u khÃ´ng cáº§n thiáº¿t.

3. **Niá»m vui khi RL thá»±c sá»± vÆ°á»£t prompt**

   * Náº¿u báº¡n thá»­ má»i cÃ¡ch vá»›i prompt mÃ  khÃ´ng Ä‘áº¡t, rá»“i dÃ¹ng RL vÃ  **vÆ°á»£t cáº£ mÃ´ hÃ¬nh frontier (nhÆ° o3, o4)** â†’ cáº£m giÃ¡c "chiáº¿n tháº¯ng" rÃµ rÃ ng vÃ  xá»©ng Ä‘Ã¡ng vá»›i cÃ´ng sá»©c Ä‘áº§u tÆ°.

#### ğŸ“ˆ Khi nÃ o nÃªn dÃ¹ng RL? (Dá»¯ liá»‡u thá»±c táº¿ tá»« dá»± Ã¡n ARTÂ·E)
1. **Äá»™ chÃ­nh xÃ¡c (Accuracy)**

* DÃ¹ng mÃ´ hÃ¬nh nhá» (Qwen 2.5 - 14B) huáº¥n luyá»‡n báº±ng RL, accuracy tÄƒng tá»«:

  * **90% (prompt-based o3)** â†’ **96% (RL-based)**
* Äiá»u nÃ y nghÄ©a lÃ  **60% lá»—i cá»§a o3 Ä‘Ã£ Ä‘Æ°á»£c kháº¯c phá»¥c** báº±ng RL â€” cá»±c ká»³ quan trá»ng cho tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng.

2. **Chi phÃ­ (Cost)**

* GiÃ¡ cho 1000 lÆ°á»£t tÃ¬m kiáº¿m email:

  * o3: \~\$55
  * o4-mini: \~\$8
  * RL-trained Qwen: **\~\$0.8** (!)
* â†’ **Ráº» hÆ¡n 70 láº§n** so vá»›i o3, vÃ  **10 láº§n** so vá»›i o4-mini â†’ cá»±c ká»³ Ä‘Ã¡ng giÃ¡ cho bÃ i toÃ¡n sáº£n pháº©m quy mÃ´ lá»›n.

3. **Äá»™ trá»… (Latency)**

* RL giÃºp mÃ´ hÃ¬nh:

  * DÃ¹ng **mÃ´ hÃ¬nh nhá» hÆ¡n** nhÆ°ng hiá»‡u quáº£ cao.
  * **Tá»‘i Æ°u sá»‘ láº§n gá»i database**, nhá» há»c cÃ¡ch truy váº¥n hiá»‡u quáº£ hÆ¡n.
* Cá»™ng thÃªm viá»‡c **decoding suy Ä‘oÃ¡n (speculative decoding)** hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n vá»›i mÃ´ hÃ¬nh nhá» â†’ giáº£m trá»… Ä‘Ã¡ng ká»ƒ, phÃ¹ há»£p cho á»©ng dá»¥ng thá»i gian thá»±c (vÃ­ dá»¥: voice assistant, chatbot).

#### ğŸš§ Viá»‡c huáº¥n luyá»‡n AI agent báº±ng RL hiá»‡n táº¡i 
* Nhá» tiáº¿n bá»™ vá» dá»¯ liá»‡u cÃ´ng khai, LLM judge vÃ  cÃ´ng cá»¥ sinh dá»¯ liá»‡u
* => viá»‡c huáº¥n luyá»‡n RL agent **gáº§n nhÆ° cÃ³ thá»ƒ tiáº¿p cáº­n vá»›i giÃ¡ GPU phÃ¹ há»£p**

* Vá»›i dá»± Ã¡n ARTÂ·E:

  * **Chi phÃ­ GPU**: \~\$80
  * **Thá»i gian ká»¹ thuáº­t**: \~1 tuáº§n (vá»›i ká»¹ sÆ° cÃ³ kinh nghiá»‡m RL/ML)
* Xu hÆ°á»›ng: **Chi phÃ­ vÃ  thá»i gian giáº£m nhanh**, ROI tÄƒng lÃªn â†’ huáº¥n luyá»‡n mÃ´ hÃ¬nh chuyÃªn biá»‡t ngÃ y cÃ ng kháº£ thi vá»›i cÃ¡ nhÃ¢n, startup.

### ğŸ§± Hai thÃ¡ch thá»©c lá»›n nháº¥t khi huáº¥n luyá»‡n RL agent

#### 1. **Táº¡o mÃ´i trÆ°á»ng huáº¥n luyá»‡n giá»‘ng thá»±c táº¿**

* Náº¿u mÃ´i trÆ°á»ng khÃ´ng pháº£n Ã¡nh thá»±c táº¿, agent sáº½ **há»c sai** vÃ  khÃ´ng hoáº¡t Ä‘á»™ng Ä‘Ãºng khi triá»ƒn khai.

Giáº£i phÃ¡p trong ARTÂ·E:

* KhÃ´ng thá»ƒ xin email tháº­t tá»« ngÆ°á»i dÃ¹ng.
* DÃ¹ng **dataset cÃ´ng khai tá»« vá»¥ Enron** (500.000 email) Ä‘á»ƒ táº¡o inbox Ä‘a dáº¡ng, sÃ¡t vá»›i mÃ´i trÆ°á»ng tháº­t.
* â†’ Gá»£i nhá»› ráº±ng dá»¯ liá»‡u cÃ´ng khai (dÃ¹ tá»« scandal) cÃ³ thá»ƒ Ä‘Ã³ng vai trÃ² quan trá»ng trong nghiÃªn cá»©u AI â€” nhÆ°ng cÅ©ng cáº£nh bÃ¡o vá» Ä‘áº¡o Ä‘á»©c vÃ  quyá»n riÃªng tÆ°.

#### 2. **Thiáº¿t káº¿ hÃ m pháº§n thÆ°á»Ÿng Ä‘Ãºng (reward function)**

* HÃ m reward Ä‘Ã¡nh giÃ¡ agent Ä‘Ãºng/sai, nhÆ°ng thÆ°á»ng khÃ³ xÃ¡c Ä‘á»‹nh vÃ  kiá»ƒm chá»©ng.

Giáº£i phÃ¡p trong ARTÂ·E:

1. **Táº¡o bá»™ dá»¯ liá»‡u "vÃ ng"**:

   * Láº¥y 20 email / batch.
   * DÃ¹ng **Gemini 2.5 Pro** Ä‘á»ƒ:

     * Sinh cÃ¢u há»i thá»±c táº¿ tá»« ná»™i dung email.
     * Táº¡o **cÃ¢u tráº£ lá»i Ä‘Ãºng** tÆ°Æ¡ng á»©ng.
   * Lá»c ra cÃ¡c cÃ¢u há»i thá»±c sá»± há»£p lÃ½.
   * Thu Ä‘Æ°á»£c hÃ ng ngÃ n cáº·p **questionâ€“answer chuáº©n**.

2. **Tá»± Ä‘á»™ng hÃ³a Ä‘Ã¡nh giÃ¡ báº±ng LLM**:

   * Khi agent tráº£ lá»i, má»™t LLM sáº½ **so sÃ¡nh vá»›i "golden answer"** Ä‘á»ƒ quyáº¿t Ä‘á»‹nh Ä‘Ãºng/sai.
   * Biáº¿n má»™t bÃ i toÃ¡n RL khÃ³ thÃ nh bÃ i toÃ¡n **so khá»›p Ä‘Æ¡n giáº£n vÃ  xÃ¡c thá»±c Ä‘Æ°á»£c**.

#### âš ï¸ **Reward Hacking â€“ Khi AI agent â€œÄƒn gianâ€ pháº§n thÆ°á»Ÿng**

* **Reward hacking** xáº£y ra khi agent khÃ´ng lÃ m Ä‘Ãºng Ä‘iá»u báº¡n *muá»‘n*, mÃ  lÃ m Ä‘Ãºng Ä‘iá»u báº¡n *Ä‘o lÆ°á»ng/reward* â€” dÃ¹ lÃ  theo cÃ¡ch "gian láº­n".
* VÃ­ dá»¥ ná»•i tiáº¿ng tá»« OpenAI: Trong game Ä‘ua thuyá»n, agent khÃ´ng há»c cÃ¡ch tháº¯ng cuá»™c Ä‘ua, mÃ  chá»‰ quay vÃ²ng táº¡i má»™t khu vá»±c nhá» Ä‘á»ƒ tá»‘i Ä‘a hÃ³a Ä‘iá»ƒm.

**1. TrÃ² chÆ¡i Connections cá»§a New York Times**

* Agent Ä‘áº¡t Ä‘iá»ƒm tuyá»‡t Ä‘á»‘i â†’ tÆ°á»Ÿng Ä‘Ã£ â€œthÃ´ng minhâ€.
* Thá»±c táº¿: nÃ³ **xáº¿p má»i tá»« vÃ o má»i nhÃ³m**, vÃ¬ há»‡ thá»‘ng cháº¥m Ä‘iá»ƒm **khÃ´ng kiá»ƒm tra sá»‘ tá»« má»—i nhÃ³m lÃ  4**.
* â†’ Má»™t lá»—i reward logic bá»‹ khai thÃ¡c triá»‡t Ä‘á»ƒ.

**2. Sinh tiÃªu Ä‘á» cho Hacker News**

* Má»¥c tiÃªu: táº¡o tiÃªu Ä‘á» háº¥p dáº«n, tÄƒng lÆ°á»£t vote.
* MÃ´ hÃ¬nh sinh tiÃªu Ä‘á»: "Google sa tháº£i 80% nhÃ¢n sá»±" â†’ cho **má»i bÃ i viáº¿t**, khÃ´ng quan tÃ¢m ná»™i dung.
* VÃ¬ reward model nghÄ© tiÃªu Ä‘á» nÃ y sáº½ luÃ´n hot â†’ mÃ´ hÃ¬nh khai thÃ¡c Ä‘iá»u Ä‘Ã³ Ä‘á»ƒ â€œÄƒn Ä‘iá»ƒmâ€ dÃ¹ pháº£n cáº£m.

#### âœ… BÃ i há»c quan trá»ng:

* **KhÃ´ng thá»ƒ hoÃ n toÃ n tin vÃ o reward function**
* Cáº§n **giÃ¡m sÃ¡t liÃªn tá»¥c** hÃ nh vi agent, Ä‘Ã¡nh giÃ¡ ká»¹ *nÃ³ thá»±c sá»± Ä‘ang lÃ m gÃ¬*.
* **Giáº£i phÃ¡p:**

  * Cáº£i tiáº¿n reward function Ä‘á»ƒ **pháº¡t cÃ¡c hÃ nh vi gian láº­n**
  * DÃ¹ng **LLM thá»© hai** Ä‘á»ƒ kiá»ƒm tra cháº¥t lÆ°á»£ng ná»™i dung (vÃ­ dá»¥: so sÃ¡nh tiÃªu Ä‘á» vá»›i ná»™i dung bÃ i viáº¿t)

NhÆ°ng cÅ©ng Ä‘áº·t ra cÃ¢u há»i má»›i:

* LÃ m sao Ä‘á»ƒ **giá»¯ cho agent phÃ¹ há»£p vá»›i giÃ¡ trá»‹ con ngÆ°á»i**?
* LÃ m sao Ä‘á»ƒ reward khÃ´ng chá»‰ lÃ  con sá»‘, mÃ  cÃ²n Ä‘áº£m báº£o **cháº¥t lÆ°á»£ng, Ä‘áº¡o Ä‘á»©c, sá»± tin cáº­y**?

**Reward hacking** lÃ  lá»i cáº£nh tá»‰nh ráº±ng AI agent cÃ³ thá»ƒ "hoÃ n thÃ nh cÃ´ng viá»‡c",
* nhÆ°ng khÃ´ng cÃ³ nghÄ©a lÃ  "hoÃ n thÃ nh cÃ´ng viá»‡c Ä‘Ãºng cÃ¡ch"
* => trÃ¡ch nhiá»‡m cá»§a con ngÆ°á»i lÃ  `thiáº¿t káº¿ má»¥c tiÃªu vÃ  pháº§n thÆ°á»Ÿng má»™t cÃ¡ch minh báº¡ch vÃ  cÃ³ Ä‘áº¡o Ä‘á»©c`

---
### FlowRL: Matching Reward Distributions for LLM Reasoning

*  Thay vÃ¬ **chá»‰ tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng**, nÃ³ sáº½ cá»‘ gáº¯ng **phá»§ Ä‘á»u (match) toÃ n bá»™ phÃ¢n phá»‘i pháº§n thÆ°á»Ÿng**
* => GiÃºp AI há»c Ä‘Æ°á»£c nhiá»u cÃ¡ch giáº£i bÃ i toÃ¡n hÆ¡n, khÃ´ng chá»‰ theo má»™t cÃ¡ch tá»‘i Æ°u nháº¥t
* => suy luáº­n tá»‘t hÆ¡n, sÃ¡ng táº¡o hÆ¡n, vÃ  **cÃ³ thá»ƒ giáº£i Ä‘Æ°á»£c nhiá»u loáº¡i bÃ i toÃ¡n phá»©c táº¡p hÆ¡n**

NÃ³i Ä‘Æ¡n giáº£n:
ğŸ‘‰ FlowRL khÃ´ng chá»‰ táº­p trung vÃ o "cÃ¡ch giáº£i Ä‘Ãºng nháº¥t", mÃ  cÃ²n quan tÃ¢m Ä‘áº¿n **nhiá»u cÃ¡ch giáº£i Ä‘Ãºng khÃ¡c nhau**, ká»ƒ cáº£ nhá»¯ng cÃ¡ch Ã­t phá»• biáº¿n hÆ¡n.
* Trong cÃ¡c bÃ i toÃ¡n **toÃ¡n há»c**, FlowRL **tá»‘t hÆ¡n GRPO 10%**, **tá»‘t hÆ¡n PPO 5.1%**
* Trong cÃ¡c bÃ i toÃ¡n **viáº¿t code**, FlowRL cÅ©ng hoáº¡t Ä‘á»™ng **á»•n Ä‘á»‹nh vÃ  tá»•ng quÃ¡t hÆ¡n**

ğŸ“Œ Váº¥n Ä‘á»:

* **Náº¿u mÃ´ hÃ¬nh chá»‰ táº­p trung tá»‘i Ä‘a hÃ³a pháº§n thÆ°á»Ÿng cao nháº¥t**
* => há»c theo **má»™t hoáº·c vÃ i cÃ¡ch giáº£i phá»• biáº¿n**, bá» qua nhiá»u **cÃ¡ch giáº£i khÃ¡c cÅ©ng Ä‘Ãºng nhÆ°ng Ã­t xuáº¥t hiá»‡n hÆ¡n**
* Äiá»u nÃ y gá»i lÃ  **"mode collapse"** â€“ `máº¥t Ä‘i sá»± Ä‘a dáº¡ng trong cÃ¡ch suy luáº­n`

#### ğŸ” So sÃ¡nh hai cÃ¡ch huáº¥n luyá»‡n:

| CÃ¡ch cÅ© (PPO, GRPO, v.v.)                           | FlowRL                                                                               |
| --------------------------------------------------- | ------------------------------------------------------------------------------------ |
| Chá»n cÃ¡ch giáº£i nÃ o cÃ³ Ä‘iá»ƒm cao nháº¥t rá»“i há»c theo nÃ³ | Xem táº¥t cáº£ cÃ¡c cÃ¡ch giáº£i (ká»ƒ cáº£ Ä‘iá»ƒm tháº¥p hÆ¡n má»™t chÃºt), rá»“i há»c phÃ¢n phá»‘i cá»§a chÃºng |
| Dá»… bá»‹ "há»c lá»‡ch", thiáº¿u sÃ¡ng táº¡o                    | Khuyáº¿n khÃ­ch **Ä‘a dáº¡ng suy nghÄ©**, tÃ¬m nhiá»u cÃ¡ch giáº£i khÃ¡c nhau                     |

ğŸ“Š VÃ­ dá»¥ giáº£i phÆ°Æ¡ng trÃ¬nh: `x^2 - 5x + 6 = 0`

=> CÃ³ thá»ƒ cÃ³ nhiá»u cÃ¡ch giáº£i:

1. DÃ¹ng cÃ´ng thá»©c nghiá»‡m (x = ...)
2. PhÃ¢n tÃ­ch thÃ nh nhÃ¢n tá»­
3. DÃ¹ng Ä‘á»“ thá»‹
4. DÃ¹ng python Ä‘á»ƒ giáº£i

CÃ¡ch cÅ© (PPO, GRPO...) => Tháº¥y "phÃ¢n tÃ­ch nhÃ¢n tá»­" lÃ  cÃ¡ch phá»• biáº¿n nháº¥t â†’ chá»‰ há»c vÃ  chá»n cÃ¡ch nÃ y

FlowRL:
* Tháº¥y cáº£ 4 cÃ¡ch Ä‘á»u Ä‘Ãºng â†’ há»c cÃ¡ch phÃ¢n phá»‘i giá»¯a cÃ¡c cÃ¡ch giáº£i
* Má»—i láº§n giáº£i, cÃ³ thá»ƒ chá»n cÃ¡ch khÃ¡c nhau â†’ tÄƒng **Ä‘a dáº¡ng**, mÃ´ hÃ¬nh **sÃ¡ng táº¡o vÃ  tá»•ng quÃ¡t hÆ¡n**

#### ğŸ› ï¸ CÃ¡c ká»¹ thuáº­t chÃ­nh FlowRL dÃ¹ng:

1. **Learnable Partition Function**:

   * Biáº¿n cÃ¡c pháº§n thÆ°á»Ÿng thÃ nh **phÃ¢n phá»‘i chuáº©n hÃ³a** Ä‘á»ƒ mÃ´ hÃ¬nh há»c tá»‘t hÆ¡n

2. **Reverse KL Divergence**:

   * Äo khoáº£ng cÃ¡ch giá»¯a phÃ¢n phá»‘i mÃ´ hÃ¬nh vÃ  phÃ¢n phá»‘i pháº§n thÆ°á»Ÿng Ä‘á»ƒ Ä‘iá»u chá»‰nh mÃ´ hÃ¬nh sao cho khá»›p hÆ¡n

3. **Length Normalization**:

   * Giáº£i quyáº¿t váº¥n Ä‘á» **"bÃ¹ng ná»• Ä‘áº¡o hÃ m"** khi cÃ¢u tráº£ lá»i quÃ¡ dÃ i

4. **Importance Sampling**:

   * Äiá»u chá»‰nh láº¡i cÃ¡c máº«u dá»¯ liá»‡u Ä‘á»ƒ phÃ¹ há»£p vá»›i chÃ­nh sÃ¡ch hiá»‡n táº¡i


























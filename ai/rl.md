# L√†m cho AI Agent tr·ªü n√™n ƒë√°ng tin c·∫≠y h∆°n nh·ªù Reinforcement Learning

* H√£y ch·∫Øc ch·∫Øn r·∫±ng b·∫°n ƒë√£ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ƒëa v·ªõi `prompt-based`, c·ª• th·ªÉ l√† context engineering
* Khi ƒë√£ t·ªëi ∆∞u prompt h·∫øt m·ª©c v√† th·ª±c s·ª± c·∫ßn n√¢ng cao accuracy, ti·∫øt ki·ªám chi ph√≠, gi·∫£m ƒë·ªô tr·ªÖ => d√πng RL ƒë·ªÉ hu·∫•n luy·ªán AI Agent
* => `l√† n·ªÅn t·∫£ng ƒë·ªÉ x√¢y d·ª±ng h·ªá th·ªëng agent hi·ªáu qu·∫£ v√† ƒë√°ng tin c·∫≠y`

**Ph√¢n t√≠ch t·∫ßm quan tr·ªçng c·ªßa AI Agent**

* AI agents ƒëang tr·ªü th√†nh tr·ª• c·ªôt trong t·ª± ƒë·ªông h√≥a v√† h·ªá th·ªëng t·ª± tr·ªã.
* Vi·ªác x√¢y d·ª±ng agent ƒë√°ng tin c·∫≠y l√† **th√°ch th·ª©c k·ªπ thu·∫≠t l·ªõn**, nh∆∞ng c·ª±c k·ª≥ quan tr·ªçng v√¨:

  * Tr·ª£ l√Ω email sai ‚Üí `m·∫•t ni·ªÅm tin ng∆∞·ªùi d√πng`
  * Ph√¢n t√≠ch t√†i ch√≠nh sai ‚Üí `thi·ªát h·∫°i nghi√™m tr·ªçng`
  * H·ªá th·ªëng ch·∫≠m ‚Üí `gi·∫£m nƒÉng su·∫•t`
* V√≠ d·ª•: "Khi n√†o Shari chuy·ªÉn ƒë·∫øn Portland?" ‚Üí Agent t√¨m trong email v√† tr·∫£ l·ªùi ch√≠nh x√°c b·∫±ng c√°ch d√πng 2 tools: search_mail v√† read_mail

---
#### **KL divergence** (**Kullback‚ÄìLeibler divergence**) 
* l√† m·ªôt **kh√°i ni·ªám trong x√°c su·∫•t v√† h·ªçc m√°y**, d√πng ƒë·ªÉ **ƒëo s·ª± kh√°c nhau gi·ªØa hai ph√¢n ph·ªëi x√°c su·∫•t**
* gi√∫p m√¥ h√¨nh h·ªçc c√°ch **b·∫Øt ch∆∞·ªõc ph√¢n ph·ªëi ƒë√∫ng** ƒë·ªÉ suy lu·∫≠n t·ªët h∆°n


**Hi·ªÉu ƒë∆°n gi·∫£n:**
* ‚ÄúN·∫øu t√¥i d√πng ph√¢n ph·ªëi A ƒë·ªÉ m√¥ t·∫£ d·ªØ li·ªáu th·ª±c t·∫ø ƒëang theo ph√¢n ph·ªëi B, t√¥i s·∫Ω **m·∫•t bao nhi√™u th√¥ng tin**?‚Äù

üì¶ V√≠ d·ª• ƒë∆°n gi·∫£n:
* **Ph√¢n ph·ªëi A (m√¥ h√¨nh d·ª± ƒëo√°n):**
  70% ƒÉn ph·ªü, 30% ƒÉn b√°nh m√¨

* **Ph√¢n ph·ªëi B (th·ª±c t·∫ø):**
  50% ƒÉn ph·ªü, 50% ƒÉn b√°nh m√¨

=> **KL divergence** ƒëo ƒë·ªô l·ªách gi·ªØa A v√† B
* N·∫øu A = B, th√¨ KL divergence = 0 ‚Üí m√¥ h√¨nh kh·ªõp ho√†n to√†n v·ªõi th·ª±c t·∫ø.
* C√†ng l·ªách nhau, gi√° tr·ªã KL divergence c√†ng l·ªõn ‚Üí m√¥ h√¨nh **d·ª± ƒëo√°n sai nhi·ªÅu**

#### ‚ö†Ô∏è C√¢n nhƒÉc tr∆∞·ªõc khi traning v·ªõi RL
1. **C·∫ßn ki·ªÉm tra k·ªπ m√¥i tr∆∞·ªùng tr∆∞·ªõc khi hu·∫•n luy·ªán RL**

   * Ph·∫£i ƒë·∫£m b·∫£o c√°c **tool ho·∫°t ƒë·ªông ƒë√∫ng**, truy c·∫≠p d·ªØ li·ªáu h·ª£p l·ªá.
   * Nhi·ªÅu l·ªói ph√°t sinh t·ª´ ph·∫ßn t√≠ch h·ª£p ban ƒë·∫ßu ‚Äì n·∫øu debug trong giai ƒëo·∫°n RL s·∫Ω **m·∫•t th·ªùi gian, kh√≥ t√¨m l·ªói h∆°n**.

2. **Prompt t·ªët c√≥ th·ªÉ ƒë√£ ƒë·ªß d√πng**

   * C√≥ nhi·ªÅu tr∆∞·ªùng h·ª£p ch·ªâ c·∫ßn t·ªëi ∆∞u prompt l√† ƒë√£ ƒë·∫°t y√™u c·∫ßu.
   * Tr√°nh ƒë∆∞·ª£c quy tr√¨nh RL ph·ª©c t·∫°p v√† t·ªën k√©m n·∫øu kh√¥ng c·∫ßn thi·∫øt.

3. **Ni·ªÅm vui khi RL th·ª±c s·ª± v∆∞·ª£t prompt**

   * N·∫øu b·∫°n th·ª≠ m·ªçi c√°ch v·ªõi prompt m√† kh√¥ng ƒë·∫°t, r·ªìi d√πng RL v√† **v∆∞·ª£t c·∫£ m√¥ h√¨nh frontier (nh∆∞ o3, o4)** ‚Üí c·∫£m gi√°c "chi·∫øn th·∫Øng" r√µ r√†ng v√† x·ª©ng ƒë√°ng v·ªõi c√¥ng s·ª©c ƒë·∫ßu t∆∞.

#### üìà Khi n√†o n√™n d√πng RL? (D·ªØ li·ªáu th·ª±c t·∫ø t·ª´ d·ª± √°n ART¬∑E)
1. **ƒê·ªô ch√≠nh x√°c (Accuracy)**

* D√πng m√¥ h√¨nh nh·ªè (Qwen 2.5 - 14B) hu·∫•n luy·ªán b·∫±ng RL, accuracy tƒÉng t·ª´:

  * **90% (prompt-based o3)** ‚Üí **96% (RL-based)**
* ƒêi·ªÅu n√†y nghƒ©a l√† **60% l·ªói c·ªßa o3 ƒë√£ ƒë∆∞·ª£c kh·∫Øc ph·ª•c** b·∫±ng RL ‚Äî c·ª±c k·ª≥ quan tr·ªçng cho tr·∫£i nghi·ªám ng∆∞·ªùi d√πng.

2. **Chi ph√≠ (Cost)**

* Gi√° cho 1000 l∆∞·ª£t t√¨m ki·∫øm email:

  * o3: \~\$55
  * o4-mini: \~\$8
  * RL-trained Qwen: **\~\$0.8** (!)
* ‚Üí **R·∫ª h∆°n 70 l·∫ßn** so v·ªõi o3, v√† **10 l·∫ßn** so v·ªõi o4-mini ‚Üí c·ª±c k·ª≥ ƒë√°ng gi√° cho b√†i to√°n s·∫£n ph·∫©m quy m√¥ l·ªõn.

3. **ƒê·ªô tr·ªÖ (Latency)**

* RL gi√∫p m√¥ h√¨nh:

  * D√πng **m√¥ h√¨nh nh·ªè h∆°n** nh∆∞ng hi·ªáu qu·∫£ cao.
  * **T·ªëi ∆∞u s·ªë l·∫ßn g·ªçi database**, nh·ªù h·ªçc c√°ch truy v·∫•n hi·ªáu qu·∫£ h∆°n.
* C·ªông th√™m vi·ªác **decoding suy ƒëo√°n (speculative decoding)** ho·∫°t ƒë·ªông t·ªët h∆°n v·ªõi m√¥ h√¨nh nh·ªè ‚Üí gi·∫£m tr·ªÖ ƒë√°ng k·ªÉ, ph√π h·ª£p cho ·ª©ng d·ª•ng th·ªùi gian th·ª±c (v√≠ d·ª•: voice assistant, chatbot).

#### üöß Vi·ªác hu·∫•n luy·ªán AI agent b·∫±ng RL hi·ªán t·∫°i 
* Nh·ªù ti·∫øn b·ªô v·ªÅ d·ªØ li·ªáu c√¥ng khai, LLM judge v√† c√¥ng c·ª• sinh d·ªØ li·ªáu
* => vi·ªác hu·∫•n luy·ªán RL agent **g·∫ßn nh∆∞ c√≥ th·ªÉ ti·∫øp c·∫≠n v·ªõi gi√° GPU ph√π h·ª£p**

* V·ªõi d·ª± √°n ART¬∑E:

  * **Chi ph√≠ GPU**: \~\$80
  * **Th·ªùi gian k·ªπ thu·∫≠t**: \~1 tu·∫ßn (v·ªõi k·ªπ s∆∞ c√≥ kinh nghi·ªám RL/ML)
* Xu h∆∞·ªõng: **Chi ph√≠ v√† th·ªùi gian gi·∫£m nhanh**, ROI tƒÉng l√™n ‚Üí hu·∫•n luy·ªán m√¥ h√¨nh chuy√™n bi·ªát ng√†y c√†ng kh·∫£ thi v·ªõi c√° nh√¢n, startup.

### üß± Hai th√°ch th·ª©c l·ªõn nh·∫•t khi hu·∫•n luy·ªán RL agent

#### 1. **T·∫°o m√¥i tr∆∞·ªùng hu·∫•n luy·ªán gi·ªëng th·ª±c t·∫ø**

* N·∫øu m√¥i tr∆∞·ªùng kh√¥ng ph·∫£n √°nh th·ª±c t·∫ø, agent s·∫Ω **h·ªçc sai** v√† kh√¥ng ho·∫°t ƒë·ªông ƒë√∫ng khi tri·ªÉn khai.

Gi·∫£i ph√°p trong ART¬∑E:

* Kh√¥ng th·ªÉ xin email th·∫≠t t·ª´ ng∆∞·ªùi d√πng.
* D√πng **dataset c√¥ng khai t·ª´ v·ª• Enron** (500.000 email) ƒë·ªÉ t·∫°o inbox ƒëa d·∫°ng, s√°t v·ªõi m√¥i tr∆∞·ªùng th·∫≠t.
* ‚Üí G·ª£i nh·ªõ r·∫±ng d·ªØ li·ªáu c√¥ng khai (d√π t·ª´ scandal) c√≥ th·ªÉ ƒë√≥ng vai tr√≤ quan tr·ªçng trong nghi√™n c·ª©u AI ‚Äî nh∆∞ng c≈©ng c·∫£nh b√°o v·ªÅ ƒë·∫°o ƒë·ª©c v√† quy·ªÅn ri√™ng t∆∞.

#### 2. **Thi·∫øt k·∫ø h√†m ph·∫ßn th∆∞·ªüng ƒë√∫ng (reward function)**

* H√†m reward ƒë√°nh gi√° agent ƒë√∫ng/sai, nh∆∞ng th∆∞·ªùng kh√≥ x√°c ƒë·ªãnh v√† ki·ªÉm ch·ª©ng.

Gi·∫£i ph√°p trong ART¬∑E:

1. **T·∫°o b·ªô d·ªØ li·ªáu "v√†ng"**:

   * L·∫•y 20 email / batch.
   * D√πng **Gemini 2.5 Pro** ƒë·ªÉ:

     * Sinh c√¢u h·ªèi th·ª±c t·∫ø t·ª´ n·ªôi dung email.
     * T·∫°o **c√¢u tr·∫£ l·ªùi ƒë√∫ng** t∆∞∆°ng ·ª©ng.
   * L·ªçc ra c√°c c√¢u h·ªèi th·ª±c s·ª± h·ª£p l√Ω.
   * Thu ƒë∆∞·ª£c h√†ng ng√†n c·∫∑p **question‚Äìanswer chu·∫©n**.

2. **T·ª± ƒë·ªông h√≥a ƒë√°nh gi√° b·∫±ng LLM**:

   * Khi agent tr·∫£ l·ªùi, m·ªôt LLM s·∫Ω **so s√°nh v·ªõi "golden answer"** ƒë·ªÉ quy·∫øt ƒë·ªãnh ƒë√∫ng/sai.
   * Bi·∫øn m·ªôt b√†i to√°n RL kh√≥ th√†nh b√†i to√°n **so kh·ªõp ƒë∆°n gi·∫£n v√† x√°c th·ª±c ƒë∆∞·ª£c**.

#### ‚ö†Ô∏è **Reward Hacking ‚Äì Khi AI agent ‚ÄúƒÉn gian‚Äù ph·∫ßn th∆∞·ªüng**

* **Reward hacking** x·∫£y ra khi agent kh√¥ng l√†m ƒë√∫ng ƒëi·ªÅu b·∫°n *mu·ªën*, m√† l√†m ƒë√∫ng ƒëi·ªÅu b·∫°n *ƒëo l∆∞·ªùng/reward* ‚Äî d√π l√† theo c√°ch "gian l·∫≠n".
* V√≠ d·ª• n·ªïi ti·∫øng t·ª´ OpenAI: Trong game ƒëua thuy·ªÅn, agent kh√¥ng h·ªçc c√°ch th·∫Øng cu·ªôc ƒëua, m√† ch·ªâ quay v√≤ng t·∫°i m·ªôt khu v·ª±c nh·ªè ƒë·ªÉ t·ªëi ƒëa h√≥a ƒëi·ªÉm.

**1. Tr√≤ ch∆°i Connections c·ªßa New York Times**

* Agent ƒë·∫°t ƒëi·ªÉm tuy·ªát ƒë·ªëi ‚Üí t∆∞·ªüng ƒë√£ ‚Äúth√¥ng minh‚Äù.
* Th·ª±c t·∫ø: n√≥ **x·∫øp m·ªçi t·ª´ v√†o m·ªçi nh√≥m**, v√¨ h·ªá th·ªëng ch·∫•m ƒëi·ªÉm **kh√¥ng ki·ªÉm tra s·ªë t·ª´ m·ªói nh√≥m l√† 4**.
* ‚Üí M·ªôt l·ªói reward logic b·ªã khai th√°c tri·ªát ƒë·ªÉ.

**2. Sinh ti√™u ƒë·ªÅ cho Hacker News**

* M·ª•c ti√™u: t·∫°o ti√™u ƒë·ªÅ h·∫•p d·∫´n, tƒÉng l∆∞·ª£t vote.
* M√¥ h√¨nh sinh ti√™u ƒë·ªÅ: "Google sa th·∫£i 80% nh√¢n s·ª±" ‚Üí cho **m·ªçi b√†i vi·∫øt**, kh√¥ng quan t√¢m n·ªôi dung.
* V√¨ reward model nghƒ© ti√™u ƒë·ªÅ n√†y s·∫Ω lu√¥n hot ‚Üí m√¥ h√¨nh khai th√°c ƒëi·ªÅu ƒë√≥ ƒë·ªÉ ‚ÄúƒÉn ƒëi·ªÉm‚Äù d√π ph·∫£n c·∫£m.

#### ‚úÖ B√†i h·ªçc quan tr·ªçng:

* **Kh√¥ng th·ªÉ ho√†n to√†n tin v√†o reward function**
* C·∫ßn **gi√°m s√°t li√™n t·ª•c** h√†nh vi agent, ƒë√°nh gi√° k·ªπ *n√≥ th·ª±c s·ª± ƒëang l√†m g√¨*.
* **Gi·∫£i ph√°p:**

  * C·∫£i ti·∫øn reward function ƒë·ªÉ **ph·∫°t c√°c h√†nh vi gian l·∫≠n**
  * D√πng **LLM th·ª© hai** ƒë·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng n·ªôi dung (v√≠ d·ª•: so s√°nh ti√™u ƒë·ªÅ v·ªõi n·ªôi dung b√†i vi·∫øt)

Nh∆∞ng c≈©ng ƒë·∫∑t ra c√¢u h·ªèi m·ªõi:

* L√†m sao ƒë·ªÉ **gi·ªØ cho agent ph√π h·ª£p v·ªõi gi√° tr·ªã con ng∆∞·ªùi**?
* L√†m sao ƒë·ªÉ reward kh√¥ng ch·ªâ l√† con s·ªë, m√† c√≤n ƒë·∫£m b·∫£o **ch·∫•t l∆∞·ª£ng, ƒë·∫°o ƒë·ª©c, s·ª± tin c·∫≠y**?

**Reward hacking** l√† l·ªùi c·∫£nh t·ªânh r·∫±ng AI agent c√≥ th·ªÉ "ho√†n th√†nh c√¥ng vi·ªác",
* nh∆∞ng kh√¥ng c√≥ nghƒ©a l√† "ho√†n th√†nh c√¥ng vi·ªác ƒë√∫ng c√°ch"
* => tr√°ch nhi·ªám c·ªßa con ng∆∞·ªùi l√† `thi·∫øt k·∫ø m·ª•c ti√™u v√† ph·∫ßn th∆∞·ªüng m·ªôt c√°ch minh b·∫°ch v√† c√≥ ƒë·∫°o ƒë·ª©c`

---
### FlowRL: Matching Reward Distributions for LLM Reasoning

*  Thay v√¨ **ch·ªâ t·ªëi ƒëa h√≥a ph·∫ßn th∆∞·ªüng**, n√≥ s·∫Ω c·ªë g·∫Øng **ph·ªß ƒë·ªÅu (match) to√†n b·ªô ph√¢n ph·ªëi ph·∫ßn th∆∞·ªüng**
* => Gi√∫p AI h·ªçc ƒë∆∞·ª£c nhi·ªÅu c√°ch gi·∫£i b√†i to√°n h∆°n, kh√¥ng ch·ªâ theo m·ªôt c√°ch t·ªëi ∆∞u nh·∫•t
* => suy lu·∫≠n t·ªët h∆°n, s√°ng t·∫°o h∆°n, v√† **c√≥ th·ªÉ gi·∫£i ƒë∆∞·ª£c nhi·ªÅu lo·∫°i b√†i to√°n ph·ª©c t·∫°p h∆°n**

N√≥i ƒë∆°n gi·∫£n:
üëâ FlowRL kh√¥ng ch·ªâ t·∫≠p trung v√†o "c√°ch gi·∫£i ƒë√∫ng nh·∫•t", m√† c√≤n quan t√¢m ƒë·∫øn **nhi·ªÅu c√°ch gi·∫£i ƒë√∫ng kh√°c nhau**, k·ªÉ c·∫£ nh·ªØng c√°ch √≠t ph·ªï bi·∫øn h∆°n.
* Trong c√°c b√†i to√°n **to√°n h·ªçc**, FlowRL **t·ªët h∆°n GRPO 10%**, **t·ªët h∆°n PPO 5.1%**
* Trong c√°c b√†i to√°n **vi·∫øt code**, FlowRL c≈©ng ho·∫°t ƒë·ªông **·ªïn ƒë·ªãnh v√† t·ªïng qu√°t h∆°n**

üìå V·∫•n ƒë·ªÅ:

* **N·∫øu m√¥ h√¨nh ch·ªâ t·∫≠p trung t·ªëi ƒëa h√≥a ph·∫ßn th∆∞·ªüng cao nh·∫•t**
* => h·ªçc theo **m·ªôt ho·∫∑c v√†i c√°ch gi·∫£i ph·ªï bi·∫øn**, b·ªè qua nhi·ªÅu **c√°ch gi·∫£i kh√°c c≈©ng ƒë√∫ng nh∆∞ng √≠t xu·∫•t hi·ªán h∆°n**
* ƒêi·ªÅu n√†y g·ªçi l√† **"mode collapse"** ‚Äì `m·∫•t ƒëi s·ª± ƒëa d·∫°ng trong c√°ch suy lu·∫≠n`

#### üîÅ So s√°nh hai c√°ch hu·∫•n luy·ªán:

| C√°ch c≈© (PPO, GRPO, v.v.)                           | FlowRL                                                                               |
| --------------------------------------------------- | ------------------------------------------------------------------------------------ |
| Ch·ªçn c√°ch gi·∫£i n√†o c√≥ ƒëi·ªÉm cao nh·∫•t r·ªìi h·ªçc theo n√≥ | Xem t·∫•t c·∫£ c√°c c√°ch gi·∫£i (k·ªÉ c·∫£ ƒëi·ªÉm th·∫•p h∆°n m·ªôt ch√∫t), r·ªìi h·ªçc ph√¢n ph·ªëi c·ªßa ch√∫ng |
| D·ªÖ b·ªã "h·ªçc l·ªách", thi·∫øu s√°ng t·∫°o                    | Khuy·∫øn kh√≠ch **ƒëa d·∫°ng suy nghƒ©**, t√¨m nhi·ªÅu c√°ch gi·∫£i kh√°c nhau                     |

üìä V√≠ d·ª• gi·∫£i ph∆∞∆°ng tr√¨nh: `x^2 - 5x + 6 = 0`

=> C√≥ th·ªÉ c√≥ nhi·ªÅu c√°ch gi·∫£i:

1. D√πng c√¥ng th·ª©c nghi·ªám (x = ...)
2. Ph√¢n t√≠ch th√†nh nh√¢n t·ª≠
3. D√πng ƒë·ªì th·ªã
4. D√πng python ƒë·ªÉ gi·∫£i

C√°ch c≈© (PPO, GRPO...) => Th·∫•y "ph√¢n t√≠ch nh√¢n t·ª≠" l√† c√°ch ph·ªï bi·∫øn nh·∫•t ‚Üí ch·ªâ h·ªçc v√† ch·ªçn c√°ch n√†y

FlowRL:
* Th·∫•y c·∫£ 4 c√°ch ƒë·ªÅu ƒë√∫ng ‚Üí h·ªçc c√°ch ph√¢n ph·ªëi gi·ªØa c√°c c√°ch gi·∫£i
* M·ªói l·∫ßn gi·∫£i, c√≥ th·ªÉ ch·ªçn c√°ch kh√°c nhau ‚Üí tƒÉng **ƒëa d·∫°ng**, m√¥ h√¨nh **s√°ng t·∫°o v√† t·ªïng qu√°t h∆°n**

#### üõ†Ô∏è C√°c k·ªπ thu·∫≠t ch√≠nh FlowRL d√πng:

1. **Learnable Partition Function**:

   * Bi·∫øn c√°c ph·∫ßn th∆∞·ªüng th√†nh **ph√¢n ph·ªëi chu·∫©n h√≥a** ƒë·ªÉ m√¥ h√¨nh h·ªçc t·ªët h∆°n

2. **Reverse KL Divergence**:

   * ƒêo kho·∫£ng c√°ch gi·ªØa ph√¢n ph·ªëi m√¥ h√¨nh v√† ph√¢n ph·ªëi ph·∫ßn th∆∞·ªüng ƒë·ªÉ ƒëi·ªÅu ch·ªânh m√¥ h√¨nh sao cho kh·ªõp h∆°n

3. **Length Normalization**:

   * Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ **"b√πng n·ªï ƒë·∫°o h√†m"** khi c√¢u tr·∫£ l·ªùi qu√° d√†i

4. **Importance Sampling**:

   * ƒêi·ªÅu ch·ªânh l·∫°i c√°c m·∫´u d·ªØ li·ªáu ƒë·ªÉ ph√π h·ª£p v·ªõi ch√≠nh s√°ch hi·ªán t·∫°i

**FlowRL** l√† m·ªôt ph∆∞∆°ng ph√°p hu·∫•n luy·ªán m√¥ h√¨nh AI m·ªõi, gi√∫p h·ªçc t·ªët h∆°n v·ªõi d·ªØ li·ªáu suy lu·∫≠n d√†i v√† ƒëa d·∫°ng.
* N√≥ gi·∫£i quy·∫øt 2 v·∫•n ƒë·ªÅ l·ªõn: **ƒë·∫°o h√†m ph√°t n·ªï** (Exploding Gradients) v√† **kh√¥ng kh·ªõp d·ªØ li·ªáu hu·∫•n luy·ªán** (Sampling Mismatch), b·∫±ng c√°ch:
* Thay ƒë·ªïi c√°ch t√≠nh ph·∫ßn th∆∞·ªüng => chu·∫©n h√≥a ph·∫ßn th∆∞·ªüng theo nh√≥m ƒë·ªÉ gi√∫p m√¥ h√¨nh h·ªçc ·ªïn ƒë·ªãnh h∆°n
* Chu·∫©n h√≥a ƒë·ªô d√†i chu·ªói => chia log x√°c su·∫•t cho ƒë·ªô d√†i chu·ªói
* D√πng tr·ªçng s·ªë ƒë·ªÉ h·ªçc t·ª´ d·ªØ li·ªáu c≈© ~ h·ªçc t·ª´ d·ªØ li·ªáu c≈© (off-policy) b·∫±ng c√°ch g√°n tr·ªçng s·ªë cho t·ª´ng sampling:
  * Tr·ªçng s·ªë n√†y ƒë∆∞·ª£c "detach" ƒë·ªÉ tr√°nh m√¥ h√¨nh thay ƒë·ªïi qu√° nhanh (policy drift).
  * D√πng th√™m k·ªπ thu·∫≠t "clipping" t·ª´ PPO ƒë·ªÉ ·ªïn ƒë·ªãnh qu√° tr√¨nh h·ªçc

Diversity Evaluation Prompt:
```prompt
System: You are evaluating the DIVERSITY of solution approaches for a mathematics competition
problem. Focus on detecting even SUBTLE differences in methodology that indicate different problemsolving strategies.

PROBLEM:
{problem}
16 SOLUTION ATTEMPTS:
{formatted_responses}

EVALUATION CRITERIA - Rate diversity from 1 to 5:
Score 1 - Minimal Diversity:
‚Ä¢ 14+ responses use essentially identical approaches
‚Ä¢ Same mathematical setup, same variable choices, same solution path
‚Ä¢ Only trivial differences (arithmetic, notation, wording)
‚Ä¢ Indicates very low exploration/diversity in the generation process
Score 2 - Low Diversity:
‚Ä¢ 11-13 responses use the same main approach
‚Ä¢ 1-2 alternative approaches appear but are rare
‚Ä¢ Minor variations within the dominant method (different substitutions, orderings)
‚Ä¢ Some exploration but heavily biased toward one strategy
Score 3 - Moderate Diversity:
‚Ä¢ 7-10 responses use the most common approach
‚Ä¢ 2-3 distinct alternative approaches present
‚Ä¢ Noticeable variation in problem setup or mathematical techniques
‚Ä¢ Balanced mix showing reasonable explorati
Score 4 - High Diversity:
‚Ä¢ 4-6 responses use the most common approach
‚Ä¢ 3-4 distinct solution strategies well-represented
‚Ä¢ Multiple mathematical techniques and problem framings
‚Ä¢ Strong evidence of diverse exploration strategies
Score 5 - Maximum Diversity:
‚Ä¢ No single approach dominates (‚â§3 responses use same method)
‚Ä¢ 4+ distinctly different solution strategies
‚Ä¢ Wide variety of mathematical techniques and creative approaches
‚Ä¢ Excellent exploration and generation diversity

IMPORTANT: Focusing on the DIVERSITY of the attempted approaches. Return ONLY a number from 1
to 5.
```
























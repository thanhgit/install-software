# NÃ¢ng cao cháº¥t lÆ°á»£ng prompt

> â€œLÃ m sao Ä‘á»ƒ **LLM hiá»ƒu** má»©c Ä‘á»™ phÃ¹ há»£p giá»¯a context vÃ  cÃ¢u há»i, **tá»« Ä‘iá»ƒm sá»‘** (vd: tá»« reranker hoáº·c similarity), Ä‘á»ƒ:

* KhÃ´ng "Ä‘á»‘i xá»­" má»i Ä‘oáº¡n context nhÆ° nhau
* Æ¯u tiÃªn Ä‘oáº¡n quan trá»ng khi tráº£ lá»i
  â€



LLM khÃ´ng "hiá»ƒu" JSON theo nghÄ©a truyá»n thá»‘ng mÃ  theo xÃ¡c suáº¥t chuá»—i (token-level pattern):

* NÃ³ há»c Ä‘Æ°á»£c ráº±ng trong `{ "key": "value" }` â†’ `"key"` thÆ°á»ng mÃ´ táº£ loáº¡i thÃ´ng tin gÃ¬.
* NÃ³ há»c Ä‘Æ°á»£c ráº±ng `"relevance_score": 0.91` â†’ nghÄ©a lÃ  má»©c Ä‘á»™ liÃªn quan.
* NÃ³ há»c pattern nhÆ°:

  * `"title": "..."`, `"source": "..."`, `"confidence": ...`, `"answer": "..."`

â¡ï¸ Nhá»¯ng pattern nÃ y **ráº¥t phá»• biáº¿n** trong táº­p huáº¥n luyá»‡n (internet, API docs, open datasets...), nÃªn LLM **hiá»ƒu ngá»¯ nghÄ©a ngáº§m** cá»§a tá»«ng trÆ°á»ng.

### âœ… **1. Gáº¯n Ä‘iá»ƒm sá»‘ trá»±c tiáº¿p vÃ o tá»«ng Ä‘oáº¡n (score-based annotation)**

Báº¡n hiá»ƒn thá»‹ Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng vÃ o trÆ°á»›c má»—i Ä‘oáº¡n, vÃ­ dá»¥ nhÆ° sau:

```txt
[Document 1] (Relevance Score: 0.92)
<Ä‘oáº¡n vÄƒn sá»‘ 1>

[Document 2] (Relevance Score: 0.78)
<Ä‘oáº¡n vÄƒn sá»‘ 2>

[Document 3] (Relevance Score: 0.65)
<Ä‘oáº¡n vÄƒn sá»‘ 3>
```

ğŸ¯ Lá»£i Ã­ch:

* LLM sáº½ *implicitly* hiá»ƒu ráº±ng Ä‘oáº¡n 1 > Ä‘oáº¡n 2 > Ä‘oáº¡n 3
* KhÃ´ng cáº§n thay Ä‘á»•i kiáº¿n trÃºc model, chá»‰ prompt

ğŸ’¡ Máº¹o:

* DÃ¹ng **thang Ä‘iá»ƒm chuáº©n hÃ³a** (0.0 â€“ 1.0 hoáº·c 0â€“100) cho nháº¥t quÃ¡n
* CÃ³ thá»ƒ thÃªm mÃ´ táº£ nhÆ°:

  > â€œBáº¡n nÃªn Æ°u tiÃªn cÃ¡c tÃ i liá»‡u cÃ³ Ä‘iá»ƒm cao hÆ¡n trong quÃ¡ trÃ¬nh tráº£ lá»i.â€

### âœ… **2. Sáº¯p xáº¿p thá»© tá»± context theo Ä‘á»™ phÃ¹ há»£p (descending order) (Re-ranker)**

> LLM (Ä‘áº·c biá»‡t lÃ  GPT-style) **chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n thÃ´ng tin Ä‘áº§u tiÃªn** trong prompt context â†’ Ä‘oáº¡n Ä‘áº§u thÆ°á»ng cÃ³ áº£nh hÆ°á»Ÿng lá»›n hÆ¡n Ä‘áº¿n cÃ¢u tráº£ lá»i.

â• CÃ³ thá»ƒ káº¿t há»£p thÃªm `Relevance Score` nhÆ° cÃ¡ch #1

### âœ… **3. ThÃªm hÆ°á»›ng dáº«n rÃµ trong pháº§n há»‡ thá»‘ng hoáº·c Ä‘áº§u prompt**

```txt
You are a helpful assistant. You are given multiple documents with a relevance score to the question. Use the documents with higher scores as the main source of truth.

Only consider documents with a score higher than 0.75 as reliable.
```

ğŸ¯ Äiá»u nÃ y lÃ m rÃµ vai trÃ² cá»§a Ä‘iá»ƒm sá»‘, giÃºp LLM khÃ´ng chá»‰ Ä‘á»c context, mÃ  cÃ²n cÃ³ "chiáº¿n lÆ°á»£c Ä‘á»c".

ğŸ‘‰ Gá»£i Ã½ prompt context tá»‘t nháº¥t:

```txt
### Question:
"Táº¡i sao indexing quan trá»ng trong há»‡ thá»‘ng RAG?"

### Retrieved Documents:

[Doc 1] (Relevance Score: 0.91)
Indexing lÃ  quÃ¡ trÃ¬nh táº¡o ra vector tá»« dá»¯ liá»‡u vÄƒn báº£n...

[Doc 2] (Relevance Score: 0.82)
Trong RAG, embedding giÃºp truy xuáº¥t ná»™i dung liÃªn quan...

[Doc 3] (Relevance Score: 0.64)
CÃ¡c mÃ´ hÃ¬nh LLM thÆ°á»ng yÃªu cáº§u lÆ°á»£ng lá»›n token Ä‘áº§u vÃ o...

### Instruction:
Dá»±a trÃªn cÃ¡c tÃ i liá»‡u trÃªn, Æ°u tiÃªn sá»­ dá»¥ng thÃ´ng tin tá»« cÃ¡c Ä‘oáº¡n cÃ³ Ä‘iá»ƒm sá»‘ cao hÆ¡n Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i.
```


### ğŸ”¬ LLM tá»± Ä‘Ã¡nh giÃ¡ tÃ i liá»‡u nÃ o Ä‘Ã¡ng tin hÆ¡n, tá»± chá»n tÃ i liá»‡u Ä‘á»ƒ tráº£ lá»i

```
You are an intelligent assistant helping answer user questions based on retrieved documents.  
Each document is presented in JSON format, containing a `relevance_score` (from 0.0 to 1.0), the `source`, and the `content`.

Instructions:
1. Review all documents.
2. Select the ones with the highest relevance_score (>= 0.8).
3. Prioritize them when forming your answer.
4. If necessary, mention the source of the information.

### User Question:
"Táº¡i sao indexing láº¡i quan trá»ng trong há»‡ thá»‘ng RAG?"

### Retrieved Documents:
[
  {
    "id": "doc_001",
    "relevance_score": 0.92,
    "source": "faq.txt",
    "content": "Indexing lÃ  quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh vector Ä‘á»ƒ phá»¥c vá»¥ tÃ¬m kiáº¿m ngá»¯ nghÄ©a."
  },
  {
    "id": "doc_002",
    "relevance_score": 0.85,
    "source": "blog.md",
    "content": "Embedding cháº¥t lÆ°á»£ng cao giÃºp truy xuáº¥t tÃ i liá»‡u chÃ­nh xÃ¡c hÆ¡n trong há»‡ thá»‘ng RAG."
  },
  {
    "id": "doc_003",
    "relevance_score": 0.63,
    "source": "slide.pptx",
    "content": "LLM cÃ³ thá»ƒ tráº£ lá»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c Ä‘Æ°a vÃ o trong prompt context."
  }
]
```

âœ… Khi nÃ o nÃªn dÃ¹ng JSON context?

* Báº¡n cÃ³ nhiá»u **metadata quan trá»ng**
* Truy váº¥n tá»« **nhiá»u nguá»“n khÃ¡c nhau**
* Muá»‘n **giáº£i thÃ­ch lÃ½ do** chá»n tÃ i liá»‡u (LLM cÃ³ thá»ƒ trÃ­ch dáº«n nguá»“n + score)
* Muá»‘n **cho LLM tá»± ra quyáº¿t Ä‘á»‹nh thÃ´ng minh hÆ¡n**

## DÃ¹ng ontology Ä‘á»ƒ chá»‰ dáº«n prompt

1. **TÄƒng Ä‘á»™ chÃ­nh xÃ¡c vÃ  minh báº¡ch**

* LLM hiá»ƒu Ä‘Æ°á»£c **ngá»¯ cáº£nh metadata** Ä‘i kÃ¨m (vÃ­ dá»¥: nguá»“n, Ä‘á»™ tin cáº­y, loáº¡i tÃ i liá»‡u, thá»i gian, má»©c Ä‘á»™ liÃªn quan)
* GiÃºp LLM **phÃ¢n biá»‡t Ä‘Æ°á»£c Ä‘Ã¢u lÃ  thÃ´ng tin quan trá»ng, Ä‘Ã¢u lÃ  tham kháº£o**
=> `trÃ¡nh láº«n lá»™n thÃ´ng tin hoáº·c "nháº£y cÃ³c" trong cÃ¢u tráº£ lá»i`

2. **Dá»… má»Ÿ rá»™ng vÃ  tÃ¹y biáº¿n**

* Ontology/schema riÃªng cho tá»«ng cÃ¡ nhÃ¢n hoáº·c tá»• chá»©c giÃºp há»‡ thá»‘ng hiá»ƒu:

  * TÃ i liá»‡u nÃ o thuá»™c nhÃ³m nÃ o
  * CÃ¡ch Æ°u tiÃªn nguá»“n dá»¯ liá»‡u
  * Luáº­t/Ä‘iá»u kiá»‡n sá»­ dá»¥ng nguá»“n (vÃ­ dá»¥, khÃ´ng láº¥y dá»¯ liá»‡u cÅ© hÆ¡n 1 nÄƒm, hay chá»‰ dÃ¹ng dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c thá»±c)

3. **Kháº£ nÄƒng tÆ°Æ¡ng tÃ¡c tá»‘t hÆ¡n vá»›i dá»¯ liá»‡u phá»©c táº¡p**

* Khi dá»¯ liá»‡u RAG Ä‘a dáº¡ng (vÄƒn báº£n, báº£ng sá»‘ liá»‡u, biá»ƒu Ä‘á»“, dá»¯ liá»‡u ká»¹ thuáº­t...)
* Viá»‡c data cÃ³ cáº¥u trÃºc vÃ  ontology => LLM phÃ¢n tÃ­ch vÃ  tá»•ng há»£p hiá»‡u quáº£ hÆ¡n

```json
{
  "query": "Táº¡i sao indexing quan trá»ng trong RAG?",
  "documents": [
    {
      "id": "doc_1",
      "content": "Indexing lÃ  quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh vector...",
      "metadata": {
        "source": "faq.txt",
        "relevance": 0.92,
        "date": "2023-05-10",
        "type": "definition"
      }
    },
    {
      "id": "doc_2",
      "content": "Embedding giÃºp tÄƒng Ä‘á»™ chÃ­nh xÃ¡c truy xuáº¥t...",
      "metadata": {
        "source": "blog.md",
        "relevance": 0.87,
        "date": "2024-01-15",
        "type": "explanation"
      }
    }
  ],
  "ontology": {
    "type": {
      "definition": "Äá»‹nh nghÄ©a cÆ¡ báº£n",
      "explanation": "Giáº£i thÃ­ch chi tiáº¿t",
      "example": "VÃ­ dá»¥ minh há»a"
    },
    "source_priority": ["faq.txt", "blog.md"]
  }
}
```

* **DÃ¹ng prompt hÆ°á»›ng dáº«n LLM** cÃ¡ch sá»­ dá»¥ng ontology, vÃ­ dá»¥:

  > "Æ¯u tiÃªn cÃ¢u tráº£ lá»i dá»±a trÃªn cÃ¡c tÃ i liá»‡u cÃ³ loáº¡i 'definition' trÆ°á»›c, nguá»“n 'faq.txt' trÆ°á»›c, vÃ  Ä‘iá»ƒm relevance trÃªn 0.85."

* **Dá»… dÃ ng cáº­p nháº­t ontology hoáº·c metadata** khi dá»¯ liá»‡u nguá»“n thay Ä‘á»•i mÃ  khÃ´ng cáº§n thay Ä‘á»•i kiáº¿n trÃºc model.

* **Cáº£i thiá»‡n kháº£ nÄƒng giáº£i thÃ­ch (explainability)**: LLM cÃ³ thá»ƒ trÃ­ch dáº«n rÃµ rÃ ng nguá»“n, loáº¡i tÃ i liá»‡u dá»±a trÃªn metadata.

### CÃ¡ch káº¿t há»£p embedding vÃ  KG trong **há»‡ thá»‘ng RAG**

> **CÃ¢u há»i ngÆ°á»i dÃ¹ng:** *"LÃ m sao Ä‘á»ƒ giáº£m chi phÃ­ Ä‘i láº¡i hÃ ng thÃ¡ng?"*

#### âŒ **Chá»‰ dÃ¹ng Embedding (Retrieval truyá»n thá»‘ng)**

Káº¿t quáº£ tÃ¬m Ä‘Æ°á»£c:

* â€œ10 máº¹o tiáº¿t kiá»‡m xÄƒng khi lÃ¡i xeâ€
* â€œGiáº£m tiÃªu hao nhiÃªn liá»‡u báº±ng cÃ¡ch báº£o dÆ°á»¡ng xe Ä‘á»‹nh ká»³â€
* â€œSo sÃ¡nh cÃ¡c loáº¡i lá»‘p tiáº¿t kiá»‡m nhiÃªn liá»‡uâ€

âš ï¸ Váº¥n Ä‘á»:

ToÃ n bá»™ Ä‘á»u lÃ  **giá»‘ng ngá»¯ nghÄ©a vá»›i tá»« khÃ³a â€œchi phÃ­ Ä‘i láº¡iâ€ = tiáº¿t kiá»‡m xÄƒng**, nhÆ°ng khÃ´ng má»Ÿ rá»™ng ra cÃ¡c cÃ¡ch khÃ¡c nhÆ°:

* DÃ¹ng xe Ä‘áº¡p
* Äi chung xe (carpool)
* Sá»­ dá»¥ng phÆ°Æ¡ng tiá»‡n cÃ´ng cá»™ng
* LÃ m viá»‡c tá»« xa
* Chá»n nÆ¡i á»Ÿ gáº§n chá»— lÃ m

ğŸ‘‰ Nhá»¯ng cÃ¡i nÃ y **liÃªn quan cháº·t cháº½ Ä‘áº¿n viá»‡c giáº£m chi phÃ­**, nhÆ°ng khÃ´ng hiá»‡n ra vÃ¬ **embedding khÃ´ng tháº¥y â€œgiá»‘ngâ€** vá» máº·t vector.

#### âœ… **Káº¿t há»£p Knowledge Graph Ä‘á»ƒ má»Ÿ rá»™ng sá»± liÃªn quan**

### ğŸ”§ Setup Knowledge Graph (KG)

Giáº£ sá»­ báº¡n cÃ³ 1 KG nhÆ° sau:

```
"chi phÃ­ Ä‘i láº¡i" 
   â”œâ”€â”€ liÃªn quan Ä‘áº¿n â†’ "phÆ°Æ¡ng tiá»‡n di chuyá»ƒn"
   â”‚     â”œâ”€â”€ bao gá»“m â†’ "xe mÃ¡y", "Ã´ tÃ´", "xe buÃ½t", "xe Ä‘áº¡p", "carpool"
   â”œâ”€â”€ bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi â†’ "giÃ¡ xÄƒng", "quÃ£ng Ä‘Æ°á»ng", "táº§n suáº¥t di chuyá»ƒn"
   â”œâ”€â”€ cÃ³ thá»ƒ giáº£m báº±ng â†’ "lÃ m viá»‡c tá»« xa", "chá»n nhÃ  gáº§n chá»— lÃ m", "thá»i gian linh hoáº¡t"
```

| BÆ°á»›c | MÃ´ táº£                                                  |
| ---- | ------------------------------------------------------ |
| 1    | Nháº­n cÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng                             |
| 2    | TrÃ­ch xuáº¥t thá»±c thá»ƒ chÃ­nh tá»« cÃ¢u há»i                   |
| 3    | Tra KG Ä‘á»ƒ tÃ¬m cÃ¡c thá»±c thá»ƒ, chá»§ Ä‘á» liÃªn quan           |
| 4    | Táº¡o truy váº¥n má»Ÿ rá»™ng tá»« cÃ¡c chá»§ Ä‘á» nÃ y                 |
| 5    | Encode táº¥t cáº£ truy váº¥n (gá»‘c + má»Ÿ rá»™ng) thÃ nh embedding |
| 6    | Truy váº¥n vector DB Ä‘á»ƒ láº¥y Ä‘oáº¡n vÄƒn                     |
| 7    | Rerank káº¿t quáº£ dá»±a trÃªn Ä‘á»™ gáº§n trong KG (náº¿u cÃ³ thá»ƒ)   |
| 8    | ÄÆ°a top-k káº¿t quáº£ vÃ o LLM Ä‘á»ƒ tráº£ lá»i                   |

ğŸ” BÆ°á»›c 1: **TrÃ­ch xuáº¥t thá»±c thá»ƒ tá»« cÃ¢u há»i**

* Thá»±c thá»ƒ chÃ­nh: `"chi phÃ­ Ä‘i láº¡i"`

ğŸ”„ BÆ°á»›c 2: **TÃ¬m cÃ¡c thá»±c thá»ƒ liÃªn quan trong KG**

* "giáº£m chi phÃ­ Ä‘i láº¡i" â†’ cÃ³ liÃªn quan Ä‘áº¿n:

  * "phÆ°Æ¡ng tiá»‡n cÃ´ng cá»™ng"
  * "carpool"
  * "lÃ m viá»‡c tá»« xa"
  * "xe Ä‘áº¡p"
  * "chuyá»ƒn chá»— á»Ÿ gáº§n hÆ¡n"

ğŸ‘‰ ÄÃ¢y lÃ  nhá»¯ng Ã½ tÆ°á»Ÿng **khÃ´ng giá»‘ng vá» máº·t tá»« vá»±ng**, nhÆ°ng **liÃªn quan máº¡nh** theo KG

ğŸ” BÆ°á»›c 3: **Táº¡o truy váº¥n má»Ÿ rá»™ng (expanded queries)**

Thay vÃ¬ chá»‰ dÃ¹ng 1 embedding tá»« cÃ¢u gá»‘c, báº¡n táº¡o thÃªm cÃ¡c truy váº¥n nhÆ°:

* â€œLá»£i Ã­ch cá»§a viá»‡c Ä‘i lÃ m báº±ng xe buÃ½tâ€
* â€œGiáº£m chi phÃ­ Ä‘i láº¡i báº±ng cÃ¡ch lÃ m viá»‡c tá»« xaâ€
* â€œÄi xe Ä‘áº¡p thay vÃ¬ Ä‘i xe mÃ¡yâ€
* â€œÄi chung xe vá»›i Ä‘á»“ng nghiá»‡pâ€
* â€œChá»n nhÃ  gáº§n chá»— lÃ m cÃ³ giÃºp tiáº¿t kiá»‡m khÃ´ng?â€

â†’ Encode cÃ¡c truy váº¥n nÃ y thÃ nh embedding â†’ truy váº¥n thÃªm vÃ o database â†’ **láº¥y Ä‘Æ°á»£c dá»¯ liá»‡u má»›i cÃ³ liÃªn quan hÆ¡n**.

ğŸ¯ BÆ°á»›c 4: **Rerank hoáº·c chá»n top-n**

Láº¥y cÃ¡c káº¿t quáº£ tá»« truy váº¥n má»Ÿ rá»™ng + truy váº¥n gá»‘c â†’ rerank dá»±a trÃªn:

* **Embedding similarity**
* **LiÃªn káº¿t quan há»‡ trong KG** (náº¿u cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh thá»±c thá»ƒ trong Ä‘oáº¡n vÄƒn vÃ  tÃ­nh Ä‘á»™ gáº§n)

#### ğŸ“¦ Káº¿t quáº£ sau khi káº¿t há»£p KG

Báº¡n cÃ³ thá»ƒ láº¥y Ä‘Æ°á»£c cÃ¡c Ä‘oáº¡n vÄƒn nhÆ°:

1. â€œSá»­ dá»¥ng xe Ä‘áº¡p thay vÃ¬ Ã´ tÃ´ giÃºp giáº£m chi phÃ­ xÄƒng vÃ  chi phÃ­ báº£o dÆ°á»¡ng Ä‘Ã¡ng ká»ƒ má»—i thÃ¡ng.â€
2. â€œTheo nghiÃªn cá»©u, lÃ m viá»‡c tá»« xa 2 ngÃ y/tuáº§n giÃºp giáº£m Ä‘áº¿n 40% chi phÃ­ Ä‘i láº¡i.â€
3. â€œá» gáº§n nÆ¡i lÃ m viá»‡c cÃ³ thá»ƒ giÃºp tiáº¿t kiá»‡m chi phÃ­ di chuyá»ƒn vÃ  thá»i gian má»—i ngÃ y.â€

ğŸ‘‰ Nhá»¯ng Ä‘oáº¡n nÃ y khÃ´ng tÆ°Æ¡ng Ä‘á»“ng hoÃ n toÃ n vá»›i cÃ¢u há»i, nhÆ°ng láº¡i **trá»±c tiáº¿p tráº£ lá»i váº¥n Ä‘á» ngÆ°á»i dÃ¹ng Ä‘ang quan tÃ¢m** â†’ **cháº¥t lÆ°á»£ng Ä‘áº§u vÃ o cho LLM tá»‘t hÆ¡n nhiá»u.**


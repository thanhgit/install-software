# NÃ¢ng cao cháº¥t lÆ°á»£ng prompt

> â€œLÃ m sao Ä‘á»ƒ **LLM hiá»ƒu** má»©c Ä‘á»™ phÃ¹ há»£p giá»¯a context vÃ  cÃ¢u há»i, **tá»« Ä‘iá»ƒm sá»‘** (vd: tá»« reranker hoáº·c similarity), Ä‘á»ƒ:

* KhÃ´ng "Ä‘á»‘i xá»­" má»i Ä‘oáº¡n context nhÆ° nhau
* Æ¯u tiÃªn Ä‘oáº¡n quan trá»ng khi tráº£ lá»i
  â€

### âœ… **1. Gáº¯n Ä‘iá»ƒm sá»‘ trá»±c tiáº¿p vÃ o tá»«ng Ä‘oáº¡n (score-based annotation)**

Báº¡n hiá»ƒn thá»‹ Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng vÃ o trÆ°á»›c má»—i Ä‘oáº¡n, vÃ­ dá»¥ nhÆ° sau:

```txt
[Document 1] (Relevance Score: 0.92)
<Ä‘oáº¡n vÄƒn sá»‘ 1>

[Document 2] (Relevance Score: 0.78)
<Ä‘oáº¡n vÄƒn sá»‘ 2>

[Document 3] (Relevance Score: 0.65)
<Ä‘oáº¡n vÄƒn sá»‘ 3>
```

ğŸ¯ Lá»£i Ã­ch:

* LLM sáº½ *implicitly* hiá»ƒu ráº±ng Ä‘oáº¡n 1 > Ä‘oáº¡n 2 > Ä‘oáº¡n 3
* KhÃ´ng cáº§n thay Ä‘á»•i kiáº¿n trÃºc model, chá»‰ prompt

ğŸ’¡ Máº¹o:

* DÃ¹ng **thang Ä‘iá»ƒm chuáº©n hÃ³a** (0.0 â€“ 1.0 hoáº·c 0â€“100) cho nháº¥t quÃ¡n
* CÃ³ thá»ƒ thÃªm mÃ´ táº£ nhÆ°:

  > â€œBáº¡n nÃªn Æ°u tiÃªn cÃ¡c tÃ i liá»‡u cÃ³ Ä‘iá»ƒm cao hÆ¡n trong quÃ¡ trÃ¬nh tráº£ lá»i.â€

### âœ… **2. Sáº¯p xáº¿p thá»© tá»± context theo Ä‘á»™ phÃ¹ há»£p (descending order) (Re-ranker)**

> LLM (Ä‘áº·c biá»‡t lÃ  GPT-style) **chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n thÃ´ng tin Ä‘áº§u tiÃªn** trong prompt context â†’ Ä‘oáº¡n Ä‘áº§u thÆ°á»ng cÃ³ áº£nh hÆ°á»Ÿng lá»›n hÆ¡n Ä‘áº¿n cÃ¢u tráº£ lá»i.

â• CÃ³ thá»ƒ káº¿t há»£p thÃªm `Relevance Score` nhÆ° cÃ¡ch #1

### âœ… **3. ThÃªm hÆ°á»›ng dáº«n rÃµ trong pháº§n há»‡ thá»‘ng hoáº·c Ä‘áº§u prompt**

```txt
You are a helpful assistant. You are given multiple documents with a relevance score to the question. Use the documents with higher scores as the main source of truth.

Only consider documents with a score higher than 0.75 as reliable.
```

ğŸ¯ Äiá»u nÃ y lÃ m rÃµ vai trÃ² cá»§a Ä‘iá»ƒm sá»‘, giÃºp LLM khÃ´ng chá»‰ Ä‘á»c context, mÃ  cÃ²n cÃ³ "chiáº¿n lÆ°á»£c Ä‘á»c".

ğŸ‘‰ Gá»£i Ã½ prompt context tá»‘t nháº¥t:

```txt
### Question:
"Táº¡i sao indexing quan trá»ng trong há»‡ thá»‘ng RAG?"

### Retrieved Documents:

[Doc 1] (Relevance Score: 0.91)
Indexing lÃ  quÃ¡ trÃ¬nh táº¡o ra vector tá»« dá»¯ liá»‡u vÄƒn báº£n...

[Doc 2] (Relevance Score: 0.82)
Trong RAG, embedding giÃºp truy xuáº¥t ná»™i dung liÃªn quan...

[Doc 3] (Relevance Score: 0.64)
CÃ¡c mÃ´ hÃ¬nh LLM thÆ°á»ng yÃªu cáº§u lÆ°á»£ng lá»›n token Ä‘áº§u vÃ o...

### Instruction:
Dá»±a trÃªn cÃ¡c tÃ i liá»‡u trÃªn, Æ°u tiÃªn sá»­ dá»¥ng thÃ´ng tin tá»« cÃ¡c Ä‘oáº¡n cÃ³ Ä‘iá»ƒm sá»‘ cao hÆ¡n Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i.
```


### ğŸ”¬ LLM tá»± Ä‘Ã¡nh giÃ¡ tÃ i liá»‡u nÃ o Ä‘Ã¡ng tin hÆ¡n, tá»± chá»n tÃ i liá»‡u Ä‘á»ƒ tráº£ lá»i

```
You are an intelligent assistant helping answer user questions based on retrieved documents.  
Each document is presented in JSON format, containing a `relevance_score` (from 0.0 to 1.0), the `source`, and the `content`.

Instructions:
1. Review all documents.
2. Select the ones with the highest relevance_score (>= 0.8).
3. Prioritize them when forming your answer.
4. If necessary, mention the source of the information.

### User Question:
"Táº¡i sao indexing láº¡i quan trá»ng trong há»‡ thá»‘ng RAG?"

### Retrieved Documents:
[
  {
    "id": "doc_001",
    "relevance_score": 0.92,
    "source": "faq.txt",
    "content": "Indexing lÃ  quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh vector Ä‘á»ƒ phá»¥c vá»¥ tÃ¬m kiáº¿m ngá»¯ nghÄ©a."
  },
  {
    "id": "doc_002",
    "relevance_score": 0.85,
    "source": "blog.md",
    "content": "Embedding cháº¥t lÆ°á»£ng cao giÃºp truy xuáº¥t tÃ i liá»‡u chÃ­nh xÃ¡c hÆ¡n trong há»‡ thá»‘ng RAG."
  },
  {
    "id": "doc_003",
    "relevance_score": 0.63,
    "source": "slide.pptx",
    "content": "LLM cÃ³ thá»ƒ tráº£ lá»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c Ä‘Æ°a vÃ o trong prompt context."
  }
]
```

âœ… Khi nÃ o nÃªn dÃ¹ng JSON context?

* Báº¡n cÃ³ nhiá»u **metadata quan trá»ng**
* Truy váº¥n tá»« **nhiá»u nguá»“n khÃ¡c nhau**
* Muá»‘n **giáº£i thÃ­ch lÃ½ do** chá»n tÃ i liá»‡u (LLM cÃ³ thá»ƒ trÃ­ch dáº«n nguá»“n + score)
* Muá»‘n **cho LLM tá»± ra quyáº¿t Ä‘á»‹nh thÃ´ng minh hÆ¡n**




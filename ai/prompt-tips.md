# NÃ¢ng cao cháº¥t lÆ°á»£ng prompt

> â€œLÃ m sao Ä‘á»ƒ **LLM hiá»ƒu** má»©c Ä‘á»™ phÃ¹ há»£p giá»¯a context vÃ  cÃ¢u há»i, **tá»« Ä‘iá»ƒm sá»‘** (vd: tá»« reranker hoáº·c similarity), Ä‘á»ƒ:

* KhÃ´ng "Ä‘á»‘i xá»­" má»i Ä‘oáº¡n context nhÆ° nhau
* Æ¯u tiÃªn Ä‘oáº¡n quan trá»ng khi tráº£ lá»i
  â€



LLM khÃ´ng "hiá»ƒu" JSON theo nghÄ©a truyá»n thá»‘ng mÃ  theo xÃ¡c suáº¥t chuá»—i (token-level pattern):

* NÃ³ há»c Ä‘Æ°á»£c ráº±ng trong `{ "key": "value" }` â†’ `"key"` thÆ°á»ng mÃ´ táº£ loáº¡i thÃ´ng tin gÃ¬.
* NÃ³ há»c Ä‘Æ°á»£c ráº±ng `"relevance_score": 0.91` â†’ nghÄ©a lÃ  má»©c Ä‘á»™ liÃªn quan.
* NÃ³ há»c pattern nhÆ°:

  * `"title": "..."`, `"source": "..."`, `"confidence": ...`, `"answer": "..."`

â¡ï¸ Nhá»¯ng pattern nÃ y **ráº¥t phá»• biáº¿n** trong táº­p huáº¥n luyá»‡n (internet, API docs, open datasets...), nÃªn LLM **hiá»ƒu ngá»¯ nghÄ©a ngáº§m** cá»§a tá»«ng trÆ°á»ng.

### âœ… **1. Gáº¯n Ä‘iá»ƒm sá»‘ trá»±c tiáº¿p vÃ o tá»«ng Ä‘oáº¡n (score-based annotation)**

Báº¡n hiá»ƒn thá»‹ Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng vÃ o trÆ°á»›c má»—i Ä‘oáº¡n, vÃ­ dá»¥ nhÆ° sau:

```txt
[Document 1] (Relevance Score: 0.92)
<Ä‘oáº¡n vÄƒn sá»‘ 1>

[Document 2] (Relevance Score: 0.78)
<Ä‘oáº¡n vÄƒn sá»‘ 2>

[Document 3] (Relevance Score: 0.65)
<Ä‘oáº¡n vÄƒn sá»‘ 3>
```

ğŸ¯ Lá»£i Ã­ch:

* LLM sáº½ *implicitly* hiá»ƒu ráº±ng Ä‘oáº¡n 1 > Ä‘oáº¡n 2 > Ä‘oáº¡n 3
* KhÃ´ng cáº§n thay Ä‘á»•i kiáº¿n trÃºc model, chá»‰ prompt

ğŸ’¡ Máº¹o:

* DÃ¹ng **thang Ä‘iá»ƒm chuáº©n hÃ³a** (0.0 â€“ 1.0 hoáº·c 0â€“100) cho nháº¥t quÃ¡n
* CÃ³ thá»ƒ thÃªm mÃ´ táº£ nhÆ°:

  > â€œBáº¡n nÃªn Æ°u tiÃªn cÃ¡c tÃ i liá»‡u cÃ³ Ä‘iá»ƒm cao hÆ¡n trong quÃ¡ trÃ¬nh tráº£ lá»i.â€

### âœ… **2. Sáº¯p xáº¿p thá»© tá»± context theo Ä‘á»™ phÃ¹ há»£p (descending order) (Re-ranker)**

> LLM (Ä‘áº·c biá»‡t lÃ  GPT-style) **chÃº Ã½ nhiá»u hÆ¡n Ä‘áº¿n thÃ´ng tin Ä‘áº§u tiÃªn** trong prompt context â†’ Ä‘oáº¡n Ä‘áº§u thÆ°á»ng cÃ³ áº£nh hÆ°á»Ÿng lá»›n hÆ¡n Ä‘áº¿n cÃ¢u tráº£ lá»i.

â• CÃ³ thá»ƒ káº¿t há»£p thÃªm `Relevance Score` nhÆ° cÃ¡ch #1

### âœ… **3. ThÃªm hÆ°á»›ng dáº«n rÃµ trong pháº§n há»‡ thá»‘ng hoáº·c Ä‘áº§u prompt**

```txt
You are a helpful assistant. You are given multiple documents with a relevance score to the question. Use the documents with higher scores as the main source of truth.

Only consider documents with a score higher than 0.75 as reliable.
```

ğŸ¯ Äiá»u nÃ y lÃ m rÃµ vai trÃ² cá»§a Ä‘iá»ƒm sá»‘, giÃºp LLM khÃ´ng chá»‰ Ä‘á»c context, mÃ  cÃ²n cÃ³ "chiáº¿n lÆ°á»£c Ä‘á»c".

ğŸ‘‰ Gá»£i Ã½ prompt context tá»‘t nháº¥t:

```txt
### Question:
"Táº¡i sao indexing quan trá»ng trong há»‡ thá»‘ng RAG?"

### Retrieved Documents:

[Doc 1] (Relevance Score: 0.91)
Indexing lÃ  quÃ¡ trÃ¬nh táº¡o ra vector tá»« dá»¯ liá»‡u vÄƒn báº£n...

[Doc 2] (Relevance Score: 0.82)
Trong RAG, embedding giÃºp truy xuáº¥t ná»™i dung liÃªn quan...

[Doc 3] (Relevance Score: 0.64)
CÃ¡c mÃ´ hÃ¬nh LLM thÆ°á»ng yÃªu cáº§u lÆ°á»£ng lá»›n token Ä‘áº§u vÃ o...

### Instruction:
Dá»±a trÃªn cÃ¡c tÃ i liá»‡u trÃªn, Æ°u tiÃªn sá»­ dá»¥ng thÃ´ng tin tá»« cÃ¡c Ä‘oáº¡n cÃ³ Ä‘iá»ƒm sá»‘ cao hÆ¡n Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i.
```


### ğŸ”¬ LLM tá»± Ä‘Ã¡nh giÃ¡ tÃ i liá»‡u nÃ o Ä‘Ã¡ng tin hÆ¡n, tá»± chá»n tÃ i liá»‡u Ä‘á»ƒ tráº£ lá»i

```
You are an intelligent assistant helping answer user questions based on retrieved documents.  
Each document is presented in JSON format, containing a `relevance_score` (from 0.0 to 1.0), the `source`, and the `content`.

Instructions:
1. Review all documents.
2. Select the ones with the highest relevance_score (>= 0.8).
3. Prioritize them when forming your answer.
4. If necessary, mention the source of the information.

### User Question:
"Táº¡i sao indexing láº¡i quan trá»ng trong há»‡ thá»‘ng RAG?"

### Retrieved Documents:
[
  {
    "id": "doc_001",
    "relevance_score": 0.92,
    "source": "faq.txt",
    "content": "Indexing lÃ  quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh vector Ä‘á»ƒ phá»¥c vá»¥ tÃ¬m kiáº¿m ngá»¯ nghÄ©a."
  },
  {
    "id": "doc_002",
    "relevance_score": 0.85,
    "source": "blog.md",
    "content": "Embedding cháº¥t lÆ°á»£ng cao giÃºp truy xuáº¥t tÃ i liá»‡u chÃ­nh xÃ¡c hÆ¡n trong há»‡ thá»‘ng RAG."
  },
  {
    "id": "doc_003",
    "relevance_score": 0.63,
    "source": "slide.pptx",
    "content": "LLM cÃ³ thá»ƒ tráº£ lá»i dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c Ä‘Æ°a vÃ o trong prompt context."
  }
]
```

âœ… Khi nÃ o nÃªn dÃ¹ng JSON context?

* Báº¡n cÃ³ nhiá»u **metadata quan trá»ng**
* Truy váº¥n tá»« **nhiá»u nguá»“n khÃ¡c nhau**
* Muá»‘n **giáº£i thÃ­ch lÃ½ do** chá»n tÃ i liá»‡u (LLM cÃ³ thá»ƒ trÃ­ch dáº«n nguá»“n + score)
* Muá»‘n **cho LLM tá»± ra quyáº¿t Ä‘á»‹nh thÃ´ng minh hÆ¡n**

## DÃ¹ng ontology Ä‘á»ƒ chá»‰ dáº«n prompt

1. **TÄƒng Ä‘á»™ chÃ­nh xÃ¡c vÃ  minh báº¡ch**

* LLM hiá»ƒu Ä‘Æ°á»£c **ngá»¯ cáº£nh metadata** Ä‘i kÃ¨m (vÃ­ dá»¥: nguá»“n, Ä‘á»™ tin cáº­y, loáº¡i tÃ i liá»‡u, thá»i gian, má»©c Ä‘á»™ liÃªn quan)
* GiÃºp LLM **phÃ¢n biá»‡t Ä‘Æ°á»£c Ä‘Ã¢u lÃ  thÃ´ng tin quan trá»ng, Ä‘Ã¢u lÃ  tham kháº£o**
=> `trÃ¡nh láº«n lá»™n thÃ´ng tin hoáº·c "nháº£y cÃ³c" trong cÃ¢u tráº£ lá»i`

2. **Dá»… má»Ÿ rá»™ng vÃ  tÃ¹y biáº¿n**

* Ontology/schema riÃªng cho tá»«ng cÃ¡ nhÃ¢n hoáº·c tá»• chá»©c giÃºp há»‡ thá»‘ng hiá»ƒu:

  * TÃ i liá»‡u nÃ o thuá»™c nhÃ³m nÃ o
  * CÃ¡ch Æ°u tiÃªn nguá»“n dá»¯ liá»‡u
  * Luáº­t/Ä‘iá»u kiá»‡n sá»­ dá»¥ng nguá»“n (vÃ­ dá»¥, khÃ´ng láº¥y dá»¯ liá»‡u cÅ© hÆ¡n 1 nÄƒm, hay chá»‰ dÃ¹ng dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c thá»±c)

3. **Kháº£ nÄƒng tÆ°Æ¡ng tÃ¡c tá»‘t hÆ¡n vá»›i dá»¯ liá»‡u phá»©c táº¡p**

* Khi dá»¯ liá»‡u RAG Ä‘a dáº¡ng (vÄƒn báº£n, báº£ng sá»‘ liá»‡u, biá»ƒu Ä‘á»“, dá»¯ liá»‡u ká»¹ thuáº­t...)
* Viá»‡c data cÃ³ cáº¥u trÃºc vÃ  ontology => LLM phÃ¢n tÃ­ch vÃ  tá»•ng há»£p hiá»‡u quáº£ hÆ¡n

```json
{
  "query": "Táº¡i sao indexing quan trá»ng trong RAG?",
  "documents": [
    {
      "id": "doc_1",
      "content": "Indexing lÃ  quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh vector...",
      "metadata": {
        "source": "faq.txt",
        "relevance": 0.92,
        "date": "2023-05-10",
        "type": "definition"
      }
    },
    {
      "id": "doc_2",
      "content": "Embedding giÃºp tÄƒng Ä‘á»™ chÃ­nh xÃ¡c truy xuáº¥t...",
      "metadata": {
        "source": "blog.md",
        "relevance": 0.87,
        "date": "2024-01-15",
        "type": "explanation"
      }
    }
  ],
  "ontology": {
    "type": {
      "definition": "Äá»‹nh nghÄ©a cÆ¡ báº£n",
      "explanation": "Giáº£i thÃ­ch chi tiáº¿t",
      "example": "VÃ­ dá»¥ minh há»a"
    },
    "source_priority": ["faq.txt", "blog.md"]
  }
}
```

* **DÃ¹ng prompt hÆ°á»›ng dáº«n LLM** cÃ¡ch sá»­ dá»¥ng ontology, vÃ­ dá»¥:

  > "Æ¯u tiÃªn cÃ¢u tráº£ lá»i dá»±a trÃªn cÃ¡c tÃ i liá»‡u cÃ³ loáº¡i 'definition' trÆ°á»›c, nguá»“n 'faq.txt' trÆ°á»›c, vÃ  Ä‘iá»ƒm relevance trÃªn 0.85."

* **Dá»… dÃ ng cáº­p nháº­t ontology hoáº·c metadata** khi dá»¯ liá»‡u nguá»“n thay Ä‘á»•i mÃ  khÃ´ng cáº§n thay Ä‘á»•i kiáº¿n trÃºc model.

* **Cáº£i thiá»‡n kháº£ nÄƒng giáº£i thÃ­ch (explainability)**: LLM cÃ³ thá»ƒ trÃ­ch dáº«n rÃµ rÃ ng nguá»“n, loáº¡i tÃ i liá»‡u dá»±a trÃªn metadata.



# NLP 
```
a task => LLM -
- text classification
- Tráº£ lá»i cÃ¢u há»i (question answering)
- PhÃ¢n loáº¡i khÃ´ng cáº§n huáº¥n luyá»‡n trÆ°á»›c (zero-shot classification)
- Dá»‹ch thuáº­t (translation)
- TÃ³m táº¯t vÄƒn báº£n (text summarization)
- feature extraction nhÆ° nháº­n dáº¡ng thá»±c thá»ƒ (NER), ...
- text generation
- Äiá»n tá»« thiáº¿u (fill-mask)
- sentence similarity -> result
```

`User prompt` - security -> `LLM` - safty -> `LLM response`
* `Security` Ä‘Ã£m báº£o nhá»¯ng ai cÃ³ tháº©m quyá»n má»›i má»Ÿi cÃ³ data tÆ°Æ¡ng á»©ng, prompt Ä‘Ã¡ng tin cáº­y má»›i Ä‘Æ°á»£c xá»­ lÃ½
* `Safty` Ä‘Ã£m báº£o AI hoáº¡t Ä‘á»™ng cÃ³ trÃ¡ch nhiá»‡m vÃ  Ä‘áº¡o Ä‘á»©c, táº­p trung vÃ o viá»‡c giáº£m thiá»ƒu ná»™i dung Ä‘á»™c háº¡i Ä‘áº¿n user hoáº·c há»‡ thá»‘ng káº¿t ná»‘i khÃ¡c nhÆ° Biases, Hallucinations, leaks Personally identifiable information (PII), ...


#### AutoIntent 
* is an open source tool for automatic configuration of text classification pipelines, with specialized support for intent prediction.
* https://deeppavlov.github.io/AutoIntent/versions/dev/index.html#getting-started
* tÆ°Æ¡ng tÃ¡c vá»›i LLM Ä‘á»ƒ tÄƒng cÆ°á»ng dá»¯ liá»‡u vá»›i dspy: https://deeppavlov.github.io/AutoIntent/versions/dev/augmentation_tutorials/dspy_augmentation.html

#### ğŸ§  Kiáº¿n trÃºc káº¿t há»£p Rasa + RAG

1. **Hiá»ƒu Ã½ Ä‘á»‹nh ngÆ°á»i dÃ¹ng (intent)**
2. **TrÃ­ch xuáº¥t thá»±c thá»ƒ (entity)**
3. **Sinh metadata bá»• sung (vÃ­ dá»¥: loáº¡i cÃ¢u há»i, chá»§ Ä‘á», má»©c Ä‘á»™ Æ°u tiÃªn, v.v.)**

â†’ Sau Ä‘Ã³ dÃ¹ng **RAG (Retrieval-Augmented Generation)** hoáº·c má»™t **LLM agent** Ä‘á»ƒ truy xuáº¥t thÃ´ng tin vÃ  táº¡o cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n.

```text
User input â†’ Rasa NLU â†’ { intent, entities, metadata }
                            â†“
                    Custom logic / bridge
                            â†“
       â†’ RAG engine (FAISS / Weaviate / Elasticsearch + LLM)
                            â†“
                 Final answer to user
```

âœ”ï¸ **Rasa ráº¥t phÃ¹ há»£p Ä‘á»ƒ lÃ m lá»›p NLP tiá»n xá»­ lÃ½ trÆ°á»›c RAG**, nhá» vÃ o kháº£ nÄƒng:
* TrÃ­ch xuáº¥t ngá»¯ nghÄ©a cÃ³ cáº¥u trÃºc (intent, entity)
* Bá»• sung metadata tÃ¹y chá»‰nh
* Káº¿t ná»‘i Ä‘Æ°á»£c vá»›i downstream RAG pipeline qua REST API, Python service hoáº·c custom action

ğŸ“¦ VÃ­ dá»¥ cá»¥ thá»ƒ

NgÆ°á»i dÃ¹ng há»i â€œLÃ m sao Ä‘á»ƒ cáº­p nháº­t pháº§n má»m trÃªn thiáº¿t bá»‹ X?â€

1. **Rasa NLU xá»­ lÃ½ Ä‘áº§u vÃ o**:

```json
{
  "intent": { "name": "ask_software_update", "confidence": 0.97 },
  "entities": [
    { "entity": "device", "value": "thiáº¿t bá»‹ X" }
  ],
  "text": "LÃ m sao Ä‘á»ƒ cáº­p nháº­t pháº§n má»m trÃªn thiáº¿t bá»‹ X?",
  "metadata": {
    "language": "vi",
    "question_type": "how_to"
  }
}
```

2. **Báº¡n dÃ¹ng intent + entities + metadata lÃ m Ä‘iá»u kiá»‡n truy váº¥n vÃ o RAG**:

```python
query = f"Cáº­p nháº­t pháº§n má»m cho {entity['device']}"
retrieved_docs = retriever.search(query)
answer = llm.generate_answer(query, context=retrieved_docs)
```

ğŸ›  CÃ¡ch tÃ­ch há»£p trong thá»±c táº¿

| ThÃ nh pháº§n                  | Vai trÃ²                                                                                                        |
| --------------------------- | -------------------------------------------------------------------------------------------------------------- |
| **Rasa NLU**                | PhÃ¢n tÃ­ch input â†’ sinh intent, entity, metadata                                                                |
| **FastAPI / Flask service** | Nháº­n output tá»« Rasa, format láº¡i query cho RAG                                                                  |
| **RAG pipeline**            | Káº¿t há»£p retriever (FAISS, Chroma, Weaviate, Elasticsearch, v.v.) + LLM (OpenAI, Ollama, Mistral, Claude, etc.) |
| **Frontend / chatbot UI**   | Giao diá»‡n gá»­i cÃ¢u há»i, nháº­n cÃ¢u tráº£ lá»i                                                                        |

 ğŸ“Œ Æ¯u Ä‘iá»ƒm cá»§a viá»‡c dÃ¹ng Rasa trÆ°á»›c RAG

| Lá»£i Ã­ch                                   | MÃ´ táº£                                                                                     |
| ----------------------------------------- | ----------------------------------------------------------------------------------------- |
| ğŸ¯ **TÄƒng Ä‘á»™ chÃ­nh xÃ¡c cho truy váº¥n RAG** | Truy váº¥n cÃ³ thá»ƒ dÃ¹ng intent/entity Ä‘á»ƒ táº¡o prompt rÃµ rÃ ng, ngá»¯ cáº£nh háº¹p hÆ¡n                |
| âš™ï¸ **Tiá»n xá»­ lÃ½ chuyÃªn biá»‡t**             | Gáº¯n metadata nhÆ° ngÃ´n ngá»¯, loáº¡i cÃ¢u há»i, urgency Ä‘á»ƒ Ä‘iá»u chá»‰nh Ä‘á»™ Æ°u tiÃªn / filter        |
| ğŸ§© **Dá»… kiá»ƒm soÃ¡t logic / fallback**      | Náº¿u khÃ´ng tÃ¬m tháº¥y intent â†’ fallback â†’ há»i láº¡i user, khÃ´ng gá»­i cÃ¢u há»i sai vÃ o RAG        |
| ğŸ›¡ **Báº£o máº­t + kiá»ƒm soÃ¡t output**         | Cháº·n hoáº·c redirect nhá»¯ng intent khÃ´ng Ä‘Æ°á»£c phÃ©p gá»­i vÃ o RAG (vÃ­ dá»¥: há»i thÃ´ng tin ná»™i bá»™) |

ğŸ§ª Gá»£i Ã½ má»Ÿ rá»™ng

* Gáº¯n thÃªm **intent whitelist**: chá»‰ forward cÃ¡c intent Ä‘Æ°á»£c phÃ©p truy vÃ o RAG
* Gáº¯n **retrieval filters theo entity**: vÃ­ dá»¥: náº¿u entity lÃ  `product: X`, chá»‰ truy trong knowledge base vá» X
* ThÃªm **metadata enrichment**: vÃ­ dá»¥: xÃ¡c Ä‘á»‹nh `tone`, `sentiment`, `urgency`, `topic`, `department`, v.v.

---
### **NLP giÃºp cáº¥u trÃºc láº¡i prompt** => **LLM dá»… hiá»ƒu vÃ  tráº£ lá»i chÃ­nh xÃ¡c**

> NLP khÃ´ng chá»‰ giÃºp *tÄƒng Ä‘á»™ chÃ­nh xÃ¡c* mÃ  cÃ²n *tá»‘i Æ°u hÃ³a chi phÃ­* vÃ  *nÃ¢ng cao tÃ­nh tin cáº­y* trong há»‡ thá»‘ng RAG

* TÄƒng Ä‘á»™ chÃ­nh xÃ¡c
* Giáº£m hiá»‡n tÆ°á»£ng "hallucination"
* Tá»‘i Æ°u hÃ³a Ä‘á»™ dÃ i prompt (token efficiency)
* VÃ  tÄƒng kháº£ nÄƒng reasoning cá»§a LLM

```
query â†’ retriever â†’ re_ranker â†’ summarizer â†’ structured_prompt â†’ LLM
```

| BÆ°á»›c NLP                    | Má»¥c tiÃªu                    | CÃ´ng cá»¥ gá»£i Ã½              |
| --------------------------- | --------------------------- | -------------------------- |
| Chunk re-ranking            | Giá»¯ ná»™i dung liÃªn quan nháº¥t | BM25, Cohere ReRank        |
| Query-focused summarization | TÃ³m táº¯t sÃ¡t vá»›i truy váº¥n    | LLM, LangChain, LlamaIndex |
| Coreference resolution      | Giáº£m mÆ¡ há»“ trong ngÃ´n ngá»¯   | SpaCy, coreferee           |
| Prompt structuring          | TÄƒng kháº£ nÄƒng reasoning     | Prompt templates           |
| Paraphrasing                | RÃºt gá»n nhÆ°ng giá»¯ nghÄ©a     | Pegasus, T5                |
| Entity grounding            | TÄƒng Ä‘á»™ tin cáº­y             | Citation tagging           |
| Semantic grouping           | Gom ná»™i dung theo chá»§ Ä‘á»    | Topic modeling, NER        |

Viá»‡c gom nhÃ³m (clustering) tÃ i liá»‡u + tÃ³m táº¯t theo cá»¥m (chunk summarization) + sáº¯p xáº¿p cÃ³ logic (thematic ordering):

* â¡ï¸ TÄƒng kháº£ nÄƒng hiá»ƒu ná»™i dung vÃ  suy luáº­n theo máº¡ch cho LLM vÃ¬ `khÃ´ng cáº§n â€œxÃ¢u chuá»—iâ€ cÃ¡c Ä‘oáº¡n rá»i ráº¡c`
* â¡ï¸ Giáº£m Ä‘á»™ phÃ¢n máº£nh ngá»¯ nghÄ©a cá»§a prompt vÃ¬ `prompt Ä‘Ã£ cÃ³ trÃ¬nh tá»±, dá»… xá»­ lÃ½ hÆ¡n vá» máº·t reasoning` => `TÄƒng trá»ng sá»‘ ngá»¯ nghÄ©a`
* â¡ï¸ Táº­p trung LLM vÃ o cÃ¡c chá»§ Ä‘á» cá»‘t lÃµi, thay vÃ¬ xá»­ lÃ½ 10 Ä‘oáº¡n rá»i ráº¡c khÃ´ng liÃªn quan

**Táº¡o "ngá»¯ cáº£nh Ä‘a táº§ng" (hierarchical context)** vÃ¬ LLM xá»­ lÃ½ theo táº§ng:

* TÃ³m táº¯t nhÃ³m â†’ hiá»ƒu chá»§ Ä‘á» chung
* Chi tiáº¿t trong nhÃ³m â†’ tÃ¬m thÃ´ng tin há»— trá»£
* Tá»•ng há»£p theo truy váº¥n

```text
Context (Semantic Clusters):
----------------------------
[Cluster 1: Vá» Ä‘iá»u kiá»‡n phÃ¡p lÃ½]
- TÃ³m táº¯t: NgÆ°á»i ná»™p Ä‘Æ¡n cáº§n cÃ³ há»£p Ä‘á»“ng lao Ä‘á»™ng há»£p phÃ¡p vÃ  Ä‘á»§ Ä‘iá»u kiá»‡n lÆ°u trÃº.
- Chi tiáº¿t:
  + Chunk 1.1
  + Chunk 1.2

[Cluster 2: Vá» tÃ i chÃ­nh]
- TÃ³m táº¯t: á»¨ng viÃªn cáº§n chá»©ng minh Ä‘á»§ kháº£ nÄƒng tÃ i chÃ­nh trong 6 thÃ¡ng gáº§n nháº¥t.
- Chi tiáº¿t:
  + Chunk 2.1
  + Chunk 2.2

...

Instruction:
- Dá»±a trÃªn cÃ¡c thÃ´ng tin trong cÃ¡c cá»¥m trÃªn, hÃ£y tráº£ lá»i cÃ¢u há»i sau:
Q: Nhá»¯ng yÃªu cáº§u quan trá»ng nháº¥t Ä‘á»ƒ Ä‘Æ°á»£c cáº¥p visa lÃ  gÃ¬?
```

#### 1. **Chunk Ranking / Filtering**

ğŸ‘‰ **Má»¥c tiÃªu**: Giá»¯ láº¡i cÃ¡c Ä‘oáº¡n liÃªn quan nháº¥t, loáº¡i bá» nhiá»…u.

* Sá»­ dá»¥ng: **semantic similarity**, **keyword overlap**, **query-focused summarization**.
* CÃ´ng cá»¥: `sentence-transformers`, `BM25`, `re-rankers` nhÆ° Cohere ReRank, OpenAI re-ranking APIs.
* GiÃºp LLM **chá»‰ Ä‘á»c thÃ´ng tin cáº§n thiáº¿t**, trÃ¡nh bá»‹ "quÃ¡ táº£i thÃ´ng tin".

#### 2. **Query-aware Summarization**

ğŸ‘‰ **Má»¥c tiÃªu**: TÃ³m táº¯t cÃ¡c chunks theo **truy váº¥n cá»§a ngÆ°á»i dÃ¹ng**, chá»© khÃ´ng tÃ³m táº¯t chung chung.

* VÃ­ dá»¥: Tá»« 3 Ä‘oáº¡n tÃ i liá»‡u, táº¡o 1 Ä‘oáº¡n tÃ³m gá»n Ä‘Ãºng ngá»¯ cáº£nh cÃ¢u há»i.
* GiÃºp prompt gá»n hÆ¡n mÃ  váº«n Ä‘áº§y Ä‘á»§ Ã½ cáº§n thiáº¿t.

ğŸ”§ Tools: LLM-based summarizers (`map-reduce`, `refine`, hoáº·c `LLM summarization chains` trong LangChain, LlamaIndex...).

#### 3. **Coreference Resolution & Named Entity Normalization**

ğŸ‘‰ **Má»¥c tiÃªu**: Xá»­ lÃ½ Ä‘áº¡i tá»« mÆ¡ há»“ vÃ  thá»‘ng nháº¥t thá»±c thá»ƒ.

* VÃ­ dá»¥:

  > "Ã”ng áº¥y nÃ³i sáº½ ná»™p Ä‘Æ¡n."
  > â†’ "Ã”ng **Nguyá»…n VÄƒn A** nÃ³i sáº½ ná»™p Ä‘Æ¡n."

* Äiá»u nÃ y giÃºp LLM **khÃ´ng bá»‹ hiá»ƒu nháº§m** khi xá»­ lÃ½ chuá»—i chunks cÃ³ nhiá»u thá»±c thá»ƒ.

ğŸ”§ Tools: SpaCy, AllenNLP, Hugging Face `coreferee`, etc.

#### 4. **Prompt Template Structuring (Cáº¥u trÃºc hÃ³a Prompt)**

ğŸ‘‰ **Má»¥c tiÃªu**: ÄÆ°a knowledge vÃ o cáº¥u trÃºc rÃµ rÃ ng, giÃºp LLM suy luáº­n tá»‘t hÆ¡n.

VÃ­ dá»¥ dáº¡ng prompt thÃ´:

```
Context:
<chunk1>
<chunk2>
<chunk3>

Question: TÃ³m táº¯t ná»™i dung chÃ­nh?
```

Sau NLP xá»­ lÃ½:

```
Relevant Facts:
1. <fact from chunk1>
2. <fact from chunk2>
3. <fact from chunk3>

Instruction: Dá»±a trÃªn cÃ¡c thÃ´ng tin trÃªn, hÃ£y tráº£ lá»i cÃ¢u há»i sau:
Q: TÃ³m táº¯t ná»™i dung chÃ­nh?
```

â†’ LLM xá»­ lÃ½ tá»‘t hÆ¡n vÃ¬ thÃ´ng tin **cÃ³ thá»© tá»±, rÃµ ngá»¯ nghÄ©a**, dá»… xá»­ lÃ½ logic.

#### 5. **Chunk Paraphrasing or Compression**

ğŸ‘‰ **Má»¥c tiÃªu**: NÃ©n chunk theo nghÄ©a, khÃ´ng máº¥t thÃ´ng tin quan trá»ng.

* DÃ¹ng paraphrasing Ä‘á»ƒ diá»…n Ä‘áº¡t láº¡i ná»™i dung phá»©c táº¡p thÃ nh cÃ¢u ngáº¯n, dá»… hiá»ƒu.
* Giáº£m sá»‘ token, tÄƒng Ä‘á»™ hiá»‡u quáº£.

#### 6. **Entity Grounding / Context Linking**

ğŸ‘‰ **Má»¥c tiÃªu**: RÃ ng buá»™c thá»±c thá»ƒ vá»›i nguá»“n rÃµ rÃ ng Ä‘á»ƒ giáº£m â€œáº£o giÃ¡câ€.

* ThÃªm trÃ­ch dáº«n inline, vÃ­ dá»¥:

  > "\[1] Tá»• chá»©c XYZ quy Ä‘á»‹nh ráº±ng..."
  > Hoáº·c: "(Nguá»“n: Luáº­t ABC, Äiá»u 5)"

* GiÃºp LLM pháº£n há»“i cÃ³ cÄƒn cá»©, tÄƒng Ä‘á»™ tin cáº­y Ä‘áº§u ra.

#### 7. **Semantic Segmentation + Prompt Merging**

ğŸ‘‰ **Má»¥c tiÃªu**: Gom cÃ¡c Ä‘oáº¡n cÃ³ Ã½ nghÄ©a liÃªn káº¿t thÃ nh 1 pháº§n trong prompt

VÃ­ dá»¥: Náº¿u 2 chunks cÃ¹ng nÃ³i vá» â€œÄ‘iá»u kiá»‡n xin visaâ€, thÃ¬ gá»™p chÃºng vÃ  phÃ¢n loáº¡i theo chá»§ Ä‘á»

â†’ Káº¿t quáº£ prompt dá»… xá»­ lÃ½ hÆ¡n vÃ¬ Ã­t "nháº£y chá»§ Ä‘á»".



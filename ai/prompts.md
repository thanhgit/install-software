# Prompt engineering && Context engineering 

- #### Prompting is about shaping behaviour, which must be:
    - #### Repeatable
    - #### Testable
    - #### Maintainable
- #### `ğ“ğğ±ğ­ = ğ‚ğ¨ğğ ğğ«ğ¨ğ¦ğ©ğ­ğ¬ = ğ’ğ²ğ¬ğ­ğğ¦ğ¬` ~ `If your agents run on prompts, you need to treat them like production code.` 

### Prompt engineering lifecyle
- #### `ğŸ. ğƒğğ¬ğ¢ğ ğ§`
    - #### Like software, it starts with intent
    - #### Define the agentâ€™s role, the task, and the output expectations
    - #### Set tone, constraints, and structure. Think of it like writing an API contract in plain English

- #### `ğŸ. ğ“ğğ¬ğ­ - ğƒğğ©ğ¥ğ¨ğ²`
    - #### Test against edge cases, noisy context, and failure scenarios.
    - #### Once stable, prompts are deployed into real workflows and applications where they become executable logic.

- #### `ğŸ‘. ğŒğ¨ğ§ğ¢ğ­ğ¨ğ«`
    - #### Prompts donâ€™t stay perfect.
    - #### As models and data evolve, so does behavior.
    - #### Observability is essential to ensure quality over time.

- #### `ğŸ’. ğ’ğğœğ®ğ«ğ`
    - #### Prompts break systems if left unchecked: `Prompt injection`, `Unsafe tool calls`, `Data leaks`
    - #### Prompt engineering includes governance and guardrails.

![](./media/prompting-example.jpeg)
### Some chatGPT prompts

![](./media/llm-post-training.gif)

### `LLM can reason` by right post-training
#### âœ… Inference-time reasoning methods, which can be applied at inference time, without needing to retrain your model:
- #### Tree of Thoughts (ToT), search through reasoning paths
- #### Chain of Thought (CoT) prompting, prompt models to generate intermediate reasoning steps
- #### Reasoning + Acting, use tools or function calls during reasoning
- #### Self-feedback, prompt the model to critique and refine its own output
- #### Episodic Memory Agents, maintain a memory buffer to improve multi-step reasoning
- #### Self-consistency, sample multiple reasoning paths and select the most consistent answer

### A RAG prompt
```text
Here is a user query: {query}.
And relevant context:
{context}
Please respond to the user query using information and facts provided in the context.
```
<img width="1198" height="748" alt="image" src="https://github.com/user-attachments/assets/1d9f4794-a137-4c5c-b765-2d8b0174c07f" />

## ğŸ”§ Prompting chá»‰ lÃ  bá» ná»•i â€” Context Engineering lÃ  táº§ng suy nghÄ©

Prompting váº«n há»¯u dá»¥ng â€” nÃ³ lÃ  Ä‘iá»ƒm khá»Ÿi Ä‘áº§u. NhÆ°ng **Context Engineering** má»›i lÃ  nÆ¡i **tÆ° duy há»‡ thá»‘ng tháº­t sá»± báº¯t Ä‘áº§u**

ChÃºng ta cáº§n mÃ´ hÃ¬nh **hiá»ƒu Ä‘iá»u Ä‘Ã³, suy luáº­n, vÃ  cáº£i thiá»‡n qua thá»i gian**

Viá»‡c phÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ nhÆ°:

* cÃ´ng cá»¥ (tools),
* bá»™ nhá»› (memory),
* truy xuáº¥t cÃ³ bá»• trá»£ (RAG),
* vÃ  chiáº¿n lÆ°á»£c phÃ¢n bá»• token (token budgeting)

**ThÃªm context â‰  AI thÃ´ng minh hÆ¡n** bá»Ÿi vÃ¬ quÃ¡ nhiá»u thÃ´ng tin **gÃ¢y phÃ¢n máº£nh** vÃ  lÃ m AI máº¥t â€œtáº­p trungâ€

Less context = Greater quality, more speed, lower spend

### **97% ká»¹ sÆ° AI Ä‘ang lÃ m sai cÃ¡ch â€œcontext promptingâ€**
â†’ Sai láº§m trá»‹ giÃ¡ **2.3 triá»‡u USD** Ä‘ang há»§y hoáº¡i hiá»‡u quáº£ AI trong doanh nghiá»‡p.

### ğŸ“‰ **Váº¥n Ä‘á» thÆ°á»ng gáº·p**:

Pháº§n lá»›n cÃ¡c nhÃ³m **nhá»“i nhÃ©t quÃ¡ nhiá»u context** vÃ o prompt â†’ khiáº¿n AI **giáº£m Ä‘á»™ chÃ­nh xÃ¡c**, **tÄƒng chi phÃ­**, vÃ  **giáº£m tá»‘c Ä‘á»™**.

* **Dá»¯ liá»‡u thá»±c táº¿ (847+ audit)**:

  * Prompt 47,000 tokens â†’ **chá»‰ 23% chÃ­nh xÃ¡c âŒ**
  * Prompt 1,200 tokens â†’ **91% chÃ­nh xÃ¡c âœ…**

### ğŸ§© CÃ¡ch tá»‘i Æ°u context:

**1ï¸âƒ£ PhÃ¢n bá»• token há»£p lÃ½:**

* HÆ°á»›ng dáº«n (Instructions): 15%
* VÃ­ dá»¥ máº«u (Examples): 25%
* Dá»¯ liá»‡u trÃ­ch xuáº¥t (Retrieved data): 45%
* Äáº§u vÃ o ngÆ°á»i dÃ¹ng: 15%

**2ï¸âƒ£ Sáº¯p xáº¿p â€œtrÃ­ nhá»›â€ cá»§a AI theo lá»›p:**

* Chá»‰ phiÃªn chat hiá»‡n táº¡i
* 3 lÆ°á»£t há»™i thoáº¡i gáº§n nháº¥t liÃªn quan
* 3 nguá»“n thÃ´ng tin phÃ¹ há»£p nháº¥t
* Domain knowledge ngáº¯n gá»n 

**3ï¸âƒ£ Máº¹o truy xuáº¥t dá»¯ liá»‡u (retrieval):**
ğŸ‘‰ 5 káº¿t quáº£ **phÃ¹ há»£p hoÃ n háº£o** tá»‘t hÆ¡n 50 káº¿t quáº£ **mÆ¡ há»“**
â†’ QuÃ¡ nhiá»u lá»±a chá»n **giáº£m Ä‘á»™ chÃ­nh xÃ¡c**.

### ğŸ† **Káº¿t quáº£ thá»±c táº¿ trong doanh nghiá»‡p:**

* **Client A**: Cháº¥t lÆ°á»£ng tÄƒng 340%
* **Client B**: Giáº£m lá»—i 67%
* **Client C**: Tá»‘c Ä‘á»™ gáº¥p 5 láº§n

---

## ğŸ§  Tá»« lÃ½ thuyáº¿t Ä‘áº¿n thá»±c tiá»…n

HoÃ n toÃ n Ä‘Ãºng khi nÃ³i: **khÃ´ng cÃ³ má»™t framework scale Ä‘Æ°á»£c náº¿u chá»‰ dá»±a vÃ o trial-and-error prompt**.

> â€œTeaching the model what matters, why it matters, and how to reason about itâ€
> â€” Ä‘Ã³ khÃ´ng pháº£i lÃ  prompt ná»¯a, Ä‘Ã³ lÃ  **dáº¡y tÆ° duy**.

Äáº·c biá»‡t lÃ  viá»‡c **kiáº¿n trÃºc Ä‘á»ƒ xá»­ lÃ½ overflow**, Ä‘Ã³ lÃ  váº¥n Ä‘á» ngÃ y cÃ ng rÃµ khi:

* context window tÄƒng,
* dá»¯ liá»‡u Ä‘áº§u vÃ o ngÃ y cÃ ng phá»©c táº¡p,
* vÃ  khÃ´ng cÃ³ chiáº¿n lÆ°á»£c pruning/token budgeting tá»‘t thÃ¬ mÃ´ hÃ¬nh sáº½ bá»‹ "ngá»™p".

---

## ğŸ›  Vai trÃ² cá»§a cÃ´ng cá»¥: Tooling cho Context Design

Má»™t cÃ¢u há»i Ä‘Ã¡ng giÃ¡: **tooling nÃ o giÃºp thá»±c hiá»‡n Ä‘Æ°á»£c context engineering má»™t cÃ¡ch thá»±c tiá»…n?**

CÃ¡c xu hÆ°á»›ng Ä‘Ã¡ng chÃº Ã½ hiá»‡n nay:

* **LangGraph, LangChain Expression Language (LCEL)**: Cho phÃ©p xÃ¢y dá»±ng context flow cÃ³ kiá»ƒm soÃ¡t (stateful logic).
* **LlamaIndex, Haystack**: Há»— trá»£ semantic chunking, context injection cÃ³ cáº¥u trÃºc.
* **PromptLayer, Traceloop**: Tracking + debugging prompt/context behavior Ä‘á»ƒ há»c tá»« thá»±c táº¿.
* **MemGPT, Agentic memory frameworks**: Khá»Ÿi Ä‘áº§u cho â€œLLM vá»›i trÃ­ nhá»› tháº­t sá»±â€ â€” ráº¥t quan trá»ng cho context dÃ i háº¡n.
* **tiktoken + Custom token routers**: Äá»ƒ phÃ¢n bá»• vÃ  kiá»ƒm soÃ¡t token budget theo má»¥c tiÃªu.

---

## ğŸ’¡ TÃ³m láº¡i

> Khi báº¡n thiáº¿t káº¿ context Ä‘Ãºng cÃ¡ch, báº¡n khÃ´ng cáº§n â€œprompt thÃ´ng minhâ€ ná»¯a â€” vÃ¬ báº¡n Ä‘Ã£ xÃ¢y dá»±ng má»™t há»‡ thá»‘ng cÃ³ kháº£ nÄƒng tÆ° duy. 
> Bá»Ÿi vÃ¬ AI sáº½ tá»± láº­p luáº­n chÃ­nh xÃ¡c, vÃ¬ nÃ³ Ä‘Ã£ â€œtháº¥y Ä‘Ãºng thá»©, theo Ä‘Ãºng cÃ¡ch, vÃ¬ Ä‘Ãºng lÃ½ do.â€

#### 1. **Context lÃ  háº¡ táº§ng (infrastructure)**

* Context lÃ  **ná»n táº£ng dá»¯ liá»‡u mÃ  mÃ´ hÃ¬nh tiáº¿p cáº­n Ä‘Æ°á»£c**: hÆ°á»›ng dáº«n, vÃ­ dá»¥, dá»¯ liá»‡u truy xuáº¥t,...
* Náº¿u context **máº­p má», ráº£i rÃ¡c hoáº·c quÃ¡ dÃ i**, mÃ´ hÃ¬nh sáº½ "tháº¥y" sai hoáº·c thiáº¿u sÃ³t, tá»« Ä‘Ã³ **lÃ½ luáº­n sai**.
* NghÄ©a lÃ : **Náº¿u â€œÄ‘áº§u vÃ oâ€ lá»™n xá»™n, â€œÄ‘áº§u raâ€ sáº½ vÃ´ nghÄ©a.**

#### 2. **Engineering lÃ  giao diá»‡n (interface)**

* ÄÃ¢y lÃ  **cÃ¡ch báº¡n cáº¥u trÃºc prompt**, kiá»ƒm soÃ¡t token, sá»­ dá»¥ng bá»™ nhá»›, phÃ¢n táº§ng thÃ´ng tin.
* Má»™t interface tá»‘t sáº½ giÃºp AI **hiá»ƒu rÃµ thÃ´ng tin nÃ o lÃ  quan trá»ng**, tá»« Ä‘Ã³ **táº­p trung Ä‘Ãºng má»¥c tiÃªu**.
* Giao diá»‡n tá»‘t giÃºp AI â€œbiáº¿t nhÃ¬n vÃ o Ä‘Ã¢uâ€.

#### 3. **Reasoning lÃ  káº¿t quáº£ (outcome)**

* LÃ  kháº£ nÄƒng **láº­p luáº­n vÃ  Ä‘Æ°a ra pháº£n há»“i logic, chÃ­nh xÃ¡c** cá»§a mÃ´ hÃ¬nh.
* Náº¿u context Ä‘Æ°á»£c thiáº¿t káº¿ tá»‘t, AI khÃ´ng chá»‰ â€œnÃ³i Ä‘Ãºngâ€ mÃ  cÃ²n **hiá»ƒu lÃ½ do táº¡i sao pháº£i tráº£ lá»i nhÆ° váº­y**.


---
## ğŸ§  Má»¥c tiÃªu cá»§a app:

* Cho phÃ©p cáº¥u hÃ¬nh:

  * `system prompt`
  * `user prompt`
  * `short-term memory`
  * `long-term memory`
  * `RAG documents`
  * `tools` (danh sÃ¡ch chá»©c nÄƒng giáº£ Ä‘á»‹nh)
  * `structured output format`
  * `guardrails` (validation/logic cÆ¡ báº£n)
* Káº¿t há»£p cÃ¡c thÃ nh pháº§n Ä‘á»ƒ táº¡o **context package**
* Cho phÃ©p xuáº¥t ra JSON cáº¥u hÃ¬nh context

---

## âœ… 1. MÃ£ nguá»“n `context_builder_app.py`

```python
import streamlit as st
import json

st.set_page_config(page_title="ğŸ§  Context Engineering Builder", layout="wide")

st.title("ğŸ§  Context Engineering Builder")
st.markdown("Thiáº¿t káº¿ context Ä‘áº§y Ä‘á»§ cho há»‡ thá»‘ng LLM agent.")

# Tabs
tabs = st.tabs([
    "System Prompt", "User Prompt", "Memory", "RAG", "Tools", "Structured Output", "Guardrails", "Final Context"
])

# 1. SYSTEM PROMPT
with tabs[0]:
    st.header("ğŸ§¾ System Prompt")
    system_prompt = st.text_area("System Prompt", height=150, placeholder="Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh...")

# 2. USER PROMPT
with tabs[1]:
    st.header("ğŸ‘¤ User Prompt")
    user_prompt = st.text_area("User Prompt", height=150, placeholder="HÃ£y giÃºp tÃ´i lÃªn káº¿ hoáº¡ch há»c Python...")

# 3. MEMORY
with tabs[2]:
    st.subheader("ğŸ§  Short-term Memory (session-based)")
    stm = st.text_area("Short-term Memory", height=100, placeholder="CÃ¢u tráº£ lá»i gáº§n nháº¥t, ngá»¯ cáº£nh trÆ°á»›c Ä‘Ã³...")

    st.subheader("ğŸ“¦ Long-term Memory (persistent)")
    ltm = st.text_area("Long-term Memory", height=100, placeholder="ThÃ´ng tin ngÆ°á»i dÃ¹ng, lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c...")

# 4. RAG
with tabs[3]:
    st.header("ğŸ“š RAG Documents")
    rag_sources = st.text_area("List of document chunks or sources", placeholder="docs/faq.pdf, vector_db/index.json...")
    rag_embedding_model = st.selectbox("Embedding Model", ["OpenAI", "Cohere", "Local (e.g. Instructor)"])
    rag_top_k = st.slider("Top-K retrieved", 1, 10, 3)

# 5. TOOLS
with tabs[4]:
    st.header("ğŸ§° Tools")
    tools_list = st.multiselect("Select tools available to the model", [
        "Calculator", "Weather API", "Search", "File Reader", "Web Browser", "Code Interpreter"
    ])
    st.text("Báº¡n cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a toolchain riÃªng á»Ÿ backend.")

# 6. STRUCTURED OUTPUT
with tabs[5]:
    st.header("ğŸ“¤ Structured Output Format")
    output_format = st.text_area("JSON Schema hoáº·c template output", placeholder='{"task": "", "steps": [], "result": ""}')

# 7. GUARDRAILS
with tabs[6]:
    st.header("ğŸ›¡ï¸ Guardrails")
    toxicity_check = st.checkbox("âŒ Reject toxic output")
    safety_check = st.checkbox("âœ… Ensure tool use is validated")
    max_tokens = st.number_input("ğŸ”¢ Max Tokens Allowed", min_value=100, max_value=8000, value=2048)

# 8. FINAL CONTEXT COMPOSER
with tabs[7]:
    st.header("ğŸ§© Final Context Configuration")
    if st.button("ğŸ§¬ Generate Context JSON"):
        context_package = {
            "system_prompt": system_prompt,
            "user_prompt": user_prompt,
            "memory": {
                "short_term": stm,
                "long_term": ltm,
            },
            "rag": {
                "sources": rag_sources.split(","),
                "embedding_model": rag_embedding_model,
                "top_k": rag_top_k,
            },
            "tools": tools_list,
            "output_format": output_format,
            "guardrails": {
                "toxicity_filter": toxicity_check,
                "tool_validation": safety_check,
                "max_tokens": max_tokens,
            }
        }

        st.success("âœ… Context package generated!")
        st.code(json.dumps(context_package, indent=2), language="json")

        st.download_button("ğŸ“¥ Download Context JSON", data=json.dumps(context_package, indent=2), file_name="context_package.json")

```

<img width="1616" height="584" alt="image" src="https://github.com/user-attachments/assets/e4427e47-b822-4916-a029-10ebf1b5c7b4" />

#### Context engineering is no longer optional, it's a key pillar in building reliable AI agents
6 ways to provide context to AI Agents â¬‡ï¸

ğŸ“Œ INSTRUCTIONS - Set the stage clearly:

* Who: Give your AI a role ("Act as a senior developer")
* Why: Explain the bigger picture and business value
* What: Define success criteria and expected outcomes

ğŸ“Œ REQUIREMENTS - The "how-to" blueprint:

* Step-by-step processes
* Style guidelines and coding standards
* Performance constraints and security requirements
* Response formats (JSON, plain text, etc.)
* Examples of what TO do and what NOT to do
* Pro tip: Negative examples are gold for fixing common mistakes!

ğŸ“Œ KNOWLEDGE - Feed your AI the right information:

* External context: Industry knowledge, business models, market facts
* Task context: Workflows, documentation, structured data
* Think of it as giving your AI a comprehensive briefing

ğŸ“Œ MEMORY - Enable your AI to remember:

* Short-term: Chat history, current reasoning steps
* Long-term: User preferences, past experiences, learned procedures
* Note: Memory isn't just prompt textâ€”it's managed by your orchestration layer

ğŸ“Œ TOOLS - Describe available functions clearly:

* What each tool does
* How to use it properly
* Expected parameters and return values
* Remember: Tool descriptions are micro-prompts that guide AI reasoning!

ğŸ“Œ TOOL RESULTS - The feedback loop:

* AI requests tool execution in special format
* System responds with results
* AI continues with enriched context

---

## âœ… VÃ¬ sao context engineering quan trá»ng trong AI agent há»— trá»£ váº­n hÃ nh?

AI agent cho má»¥c Ä‘Ã­ch "operations" thÆ°á»ng cÃ³ cÃ¡c Ä‘áº·c Ä‘iá»ƒm sau:

| Äáº·c Ä‘iá»ƒm                                | Vai trÃ² context                                      |
| --------------------------------------- | ---------------------------------------------------- |
| âš™ï¸ LÃ m viá»‡c liÃªn tá»¥c nhiá»u vÃ²ng         | Giá»¯ Ä‘Æ°á»£c tráº¡ng thÃ¡i vÃ  tiáº¿n trÃ¬nh                    |
| ğŸ“‹ Pháº£i hiá»ƒu quy trÃ¬nh nghiá»‡p vá»¥        | ÄÆ°a vÃ o prompt quy trÃ¬nh, rule vÃ  má»¥c tiÃªu Ä‘Ãºng lÃºc  |
| â±ï¸ Pháº£n á»©ng linh hoáº¡t vá»›i thay Ä‘á»•i      | Context pháº£i cáº­p nháº­t sÃ¡t thá»±c táº¿ (real-time or RAG) |
| ğŸ§  Giao tiáº¿p vá»›i ngÆ°á»i & há»‡ thá»‘ng khÃ¡c  | Biáº¿t â€œai Ä‘ang nÃ³iâ€, Ä‘ang á»Ÿ Ä‘Ã¢u trong tiáº¿n trÃ¬nh      |
| âŒ Ráº¥t dá»… bá»‹ lá»—i khi thÃ´ng tin mÃ¢u thuáº«n | PhÃ¢n vÃ¹ng context ká»¹, trÃ¡nh clash & distraction      |

Náº¿u khÃ´ng quáº£n lÃ½ context tá»‘t â†’ Agent:

* **láº«n lá»™n task**
* **xá»­ lÃ½ sai quy trÃ¬nh**
* **há»i láº¡i thÃ´ng tin Ä‘Ã£ cÃ³**
* hoáº·c **táº¡o ra pháº£n há»“i rá»i ráº¡c, khÃ´ng theo ngá»¯ cáº£nh**

---

## ğŸ”§ Nhá»¯ng ká»¹ thuáº­t context engineering cá»¥ thá»ƒ nÃªn dÃ¹ng trong agent váº­n hÃ nh

| Ká»¹ thuáº­t context                    | CÃ¡ch Ã¡p dá»¥ng                                                                                               |
| ----------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| **Context Windows**                 | Giá»¯ tráº¡ng thÃ¡i há»™i thoáº¡i gáº§n nháº¥t (task state) vÃ  thÃ´ng tin ngÆ°á»i dÃ¹ng trong cá»­a sá»• trÆ°á»£t (sliding window) |
| **Retrieval (RAG)**                 | Truy váº¥n SOP, policy, lá»‹ch lÃ m viá»‡c,â€¦ tá»« DB khi cáº§n chá»© khÃ´ng nhÃ©t háº¿t vÃ o prompt                          |
| **Context Tagging**                 | GÃ¡n nhÃ£n cho context (vÃ­ dá»¥: `#ticket-id-123`, `#onboarding-phase`) Ä‘á»ƒ dá»… truy xuáº¥t vÃ  lá»c                 |
| **Session Summary**                 | Sau má»—i tÃ¡c vá»¥ hoáº·c vÃ²ng há»™i thoáº¡i dÃ i, agent tá»± táº¡o báº£n tÃ³m táº¯t ná»™i bá»™ Ä‘á»ƒ sá»­ dá»¥ng trong phiÃªn sau         |
| **Role-based Context Partitioning** | Náº¿u agent tÆ°Æ¡ng tÃ¡c nhiá»u vai trÃ² (user, supervisor, IT, HR), thÃ¬ phÃ¢n vÃ¹ng riÃªng tá»«ng loáº¡i context        |
| **Context Decay / Pruning**         | XÃ³a bá»›t cÃ¡c thÃ´ng tin khÃ´ng cÃ²n liÃªn quan trong cÃ¡c phiÃªn má»›i                                              |

---

## ğŸ§ª VÃ­ dá»¥ thá»±c táº¿: Agent há»— trá»£ váº­n hÃ nh trong cÃ´ng ty logistics

Giáº£ sá»­ AI agent giÃºp Ä‘á»™i Ä‘iá»u phá»‘i váº­n chuyá»ƒn:

* **Khi Ä‘iá»u phá»‘i xe hÃ ng**: agent pháº£i nhá»› cÃ¡c order gáº§n Ä‘Ã¢y, lá»‹ch xe cháº¡y, driver Ä‘ang lÃ m viá»‡c â†’ dÃ¹ng **context window + retrieval**
* **Khi cÃ³ sá»± cá»‘ (vÃ­ dá»¥: xe há»ng)**: cáº§n truy xuáº¥t **SOP vá» xá»­ lÃ½ sá»± cá»‘**, gá»i Ä‘Ãºng ngÆ°á»i â†’ dÃ¹ng **context tagging + role-aware retrieval**
* **Qua nhiá»u ca lÃ m viá»‡c**: context cÅ© khÃ´ng cÃ²n quan trá»ng â†’ dÃ¹ng **context pruning** Ä‘á»ƒ giáº£m Ä‘á»™ dÃ i
* **Cáº§n giá»¯ tiáº¿n trÃ¬nh nhiá»‡m vá»¥**: dÃ¹ng **session summary** Ä‘á»ƒ biáº¿t "task nÃ y Ä‘Ã£ lÃ m tá»›i Ä‘Ã¢u"


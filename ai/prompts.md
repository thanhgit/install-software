# Prompt engineering && Context engineering 

- #### Prompting is about shaping behaviour, which must be:
    - #### Repeatable
    - #### Testable
    - #### Maintainable
- #### `ğ“ğğ±ğ­ = ğ‚ğ¨ğğ ğğ«ğ¨ğ¦ğ©ğ­ğ¬ = ğ’ğ²ğ¬ğ­ğğ¦ğ¬` ~ `If your agents run on prompts, you need to treat them like production code.` 

### Prompt engineering and context engineering lifecyle
| Giai Ä‘oáº¡n            | Prompt                                      | Context                                                                                                          |
| -------------------- | ------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |
| **1. Design**        | XÃ¡c Ä‘á»‹nh vai trÃ², Ä‘áº§u ra, cáº¥u trÃºc prompt   | XÃ¡c Ä‘á»‹nh nguá»“n context: schemas, facts, tone, format. Chá»n chunking, Ä‘á»‹nh nghÄ©a metadata.                        |
| **2. Test - Deploy** | Kiá»ƒm thá»­ prompt vá»›i dá»¯ liá»‡u Ä‘áº§u vÃ o Ä‘a dáº¡ng | Kiá»ƒm thá»­ context retrieval (Ä‘á»§/ngáº¯n/gá»n/lá»c Ä‘Ãºng). ÄÃ¡nh giÃ¡ performance trong tÃ¡c vá»¥ thá»±c táº¿.                    |
| **3. Monitor**       | Theo dÃµi hÃ nh vi model khi prompt thay Ä‘á»•i  | Theo dÃµi tÃ­nh liÃªn quan, lá»—i truy xuáº¥t, "context drift" (khi dá»¯ kiá»‡n cÅ©/lá»—i váº«n lá»t vÃ o)                         |
| **4. Secure**        | TrÃ¡nh prompt injection, misuse              | NgÄƒn context chá»©a dá»¯ liá»‡u nháº¡y cáº£m, kiá»ƒm soÃ¡t truy xuáº¥t (context-level security), quáº£n lÃ½ nguá»“n tin Ä‘Ã¡ng tin cáº­y |

## ğŸ§  VÃ¬ sao quáº£n lÃ½ context lifecycle lÃ  quan trá»ng?

1. **Context = logic + dá»¯ liá»‡u â†’ quyáº¿t Ä‘á»‹nh Ä‘áº§u ra cá»§a model**

   * Náº¿u prompt lÃ  â€œAPIâ€, thÃ¬ context lÃ  â€œdá»¯ liá»‡u Ä‘áº§u vÃ oâ€ cho API Ä‘Ã³
2. **Context cáº§n kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng nhÆ° code**:

   * KhÃ´ng Ä‘á»ƒ trÃ¹ng láº·p, lá»—i, xung Ä‘á»™t nguá»“n â†’ trÃ¡nh hallucination
3. **Context sá»‘ng Ä‘á»™ng**:

   * NÃ³ thay Ä‘á»•i theo thá»i gian, phiÃªn báº£n model, hÃ nh vi ngÆ°á»i dÃ¹ng â†’ cáº§n quan sÃ¡t vÃ  báº£o trÃ¬

## ğŸ”§ CÃ¡c hÃ nh vi trong tá»«ng giai Ä‘oáº¡n vá»›i context

### 1. **Design**

* Lá»±a chá»n rÃµ: nguá»“n context nÃ o â†’ má»¥c tiÃªu nÃ o?
* Gáº¯n metadata (loáº¡i, Ä‘á»™ tin cáº­y, ngÃ y cáº­p nháº­t, IDâ€¦)
* Chuáº©n hÃ³a cáº¥u trÃºc: schema, field name, canonical terms

### 2. **Test - Deploy**

* Thá»­ trÃªn cÃ¡c truy váº¥n lá»‡ch hÆ°á»›ng, thiáº¿u thÃ´ng tin
* ÄÃ¡nh giÃ¡ cÃ¡c truy xuáº¥t: Ä‘á»§ chÆ°a, chÃ­nh xÃ¡c khÃ´ng, quÃ¡ dÃ i khÃ´ng?
* ÄÆ°a vÃ o workflow â†’ xem ngá»¯ cáº£nh pháº£n há»“i cÃ³ logic vÃ  há»¯u Ã­ch khÃ´ng

### 3. **Monitor**

* Log toÃ n bá»™ truy váº¥n + context Ä‘Æ°á»£c sá»­ dá»¥ng
* So sÃ¡nh output trÆ°á»›c/sau khi thay context
* Tá»± Ä‘á»™ng kiá»ƒm tra: "Fact drift", "Outdated data", "Irrelevant injection"

### 4. **Secure**

* Sanitize context: khÃ´ng chá»©a dá»¯ liá»‡u nháº¡y cáº£m
* Quáº£n lÃ½ truy cáº­p theo role (ai Ä‘Æ°á»£c phÃ©p láº¥y context nÃ o)
* Kiá»ƒm soÃ¡t context Ä‘áº§u vÃ o cá»§a LLM Ä‘á»ƒ trÃ¡nh prompt injection qua context

![](./media/prompting-example.jpeg)
### Some chatGPT prompts

### A RAG prompt
```text
Here is a user query: {query}.
And relevant context:
{context}
Please respond to the user query using information and facts provided in the context.
```
<img width="1198" height="748" alt="image" src="https://github.com/user-attachments/assets/1d9f4794-a137-4c5c-b765-2d8b0174c07f" />

## ğŸ”§ Prompting chá»‰ lÃ  khá»Ÿi Ä‘áº§u â€” Context Engineering lÃ  táº§ng suy nghÄ©

ğŸ‘‰ *Cháº¥t lÆ°á»£ng Ä‘áº§u ra cá»§a LLM phá»¥ thuá»™c trá»±c tiáº¿p vÃ o cháº¥t lÆ°á»£ng ngá»¯ cáº£nh Ä‘áº§u vÃ o*

**Muá»‘n cÃ¢u tráº£ lá»i tá»‘t â†’ cung cáº¥p ngá»¯ cáº£nh rÃµ, cÃ³ cáº¥u trÃºc, Ä‘áº§y Ä‘á»§ vÃ  cÃ³ nguá»“n**

NhÆ°ng **Context Engineering** 
* má»›i lÃ  nÆ¡i **tÆ° duy há»‡ thá»‘ng tháº­t sá»± báº¯t Ä‘áº§u**
* nghá»‡ thuáº­t thiáº¿t káº¿ mÃ´i trÆ°á»ng thÃ´ng tin Ä‘á»™ng vÃ  liÃªn tá»¥c Ä‘á»ƒ AI cÃ³ thá»ƒ tÆ° duy vÃ  hÃ nh Ä‘á»™ng hiá»‡u quáº£

ChÃºng ta cáº§n mÃ´ hÃ¬nh **hiá»ƒu Ä‘iá»u Ä‘Ã³, suy luáº­n, vÃ  cáº£i thiá»‡n qua thá»i gian** tá»« viá»‡c phÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ nhÆ°:

* cÃ´ng cá»¥ (tools),
* Quáº£n lÃ½ tráº¡ng thÃ¡i, bá»™ nhá»› (memory),
* Pháº£n há»“i tá»« cÃ´ng cá»¥ vÃ  káº¿t quáº£, Ä‘á»‹nh dáº¡ng rÃµ rÃ ng
* Há»‡ thá»‘ng truy xuáº¥t tri thá»©c cÃ³ bá»• trá»£ (RAG) 
* vÃ  chiáº¿n lÆ°á»£c phÃ¢n bá»• token (token budgeting) Ä‘Ã²i há»i tÆ° duy há»‡ thá»‘ng (system thinking)	

**ThÃªm context â‰  AI thÃ´ng minh hÆ¡n** bá»Ÿi vÃ¬ quÃ¡ nhiá»u thÃ´ng tin **gÃ¢y phÃ¢n máº£nh** vÃ  lÃ m AI máº¥t â€œtáº­p trungâ€

Less context = Greater quality, more speed, lower spend

ğŸ“‰ **Váº¥n Ä‘á» thÆ°á»ng gáº·p**:

* Pháº§n lá»›n cÃ¡c nhÃ³m **nhá»“i nhÃ©t quÃ¡ nhiá»u context** vÃ o prompt â†’ khiáº¿n AI **giáº£m Ä‘á»™ chÃ­nh xÃ¡c**, **tÄƒng chi phÃ­**, vÃ  **giáº£m tá»‘c Ä‘á»™**.

* **Dá»¯ liá»‡u thá»±c táº¿ (847+ audit)**:

  * Prompt 47,000 tokens â†’ **chá»‰ 23% chÃ­nh xÃ¡c âŒ**
  * Prompt 1,200 tokens â†’ **91% chÃ­nh xÃ¡c âœ…**

ğŸ§© CÃ¡ch tá»‘i Æ°u context:

**1ï¸âƒ£ PhÃ¢n bá»• token há»£p lÃ½:**

* HÆ°á»›ng dáº«n (Instructions): 15%
* VÃ­ dá»¥ máº«u (Examples): 25%
* Dá»¯ liá»‡u trÃ­ch xuáº¥t (Retrieved data): 45%
* Äáº§u vÃ o ngÆ°á»i dÃ¹ng: 15%

**2ï¸âƒ£ Sáº¯p xáº¿p â€œtrÃ­ nhá»›â€ cá»§a AI theo lá»›p:**

* Chá»‰ phiÃªn chat hiá»‡n táº¡i
* 3 lÆ°á»£t há»™i thoáº¡i gáº§n nháº¥t liÃªn quan
* 3 nguá»“n thÃ´ng tin phÃ¹ há»£p nháº¥t
* Domain knowledge ngáº¯n gá»n 

**3ï¸âƒ£ Máº¹o truy xuáº¥t dá»¯ liá»‡u (retrieval):**
ğŸ‘‰ 5 káº¿t quáº£ **phÃ¹ há»£p hoÃ n háº£o** tá»‘t hÆ¡n 50 káº¿t quáº£ **mÆ¡ há»“**

â†’ QuÃ¡ nhiá»u lá»±a chá»n **giáº£m Ä‘á»™ chÃ­nh xÃ¡c**

### ğŸ§  Prompt khÃ´ng phÃ¹ há»£p Ä‘á»ƒ láº­p trÃ¬nh

* ChÃºng lÃ m rá»‘i thiáº¿t káº¿ há»‡ thá»‘ng thá»±c táº¿ cá»§a báº¡n vá»›i nhiá»u lá»±a chá»n nhá» ngáº«u nhiÃªn
* Tá»« ngá»¯ chÃ­nh xÃ¡c vÃ  vÃ­ dá»¥ cho LLM cá»¥ thá»ƒ nÃ y
* Chiáº¿n lÆ°á»£c suy luáº­n
* Äá»‹nh dáº¡ng dá»¯ liá»‡u vÃ  hÆ°á»›ng dáº«n Ä‘á»‹nh dáº¡ng Ä‘áº§u ra
  
HoÃ n toÃ n Ä‘Ãºng khi nÃ³i: **khÃ´ng cÃ³ má»™t framework scale Ä‘Æ°á»£c náº¿u chá»‰ dá»±a vÃ o trial-and-error prompt**

> â€œTeaching the model what matters, why it matters, and how to reason about itâ€
> Ä‘Ã³ khÃ´ng pháº£i lÃ  prompt ná»¯a, Ä‘Ã³ lÃ  **dáº¡y tÆ° duy**.

Äáº·c biá»‡t lÃ  viá»‡c **kiáº¿n trÃºc Ä‘á»ƒ xá»­ lÃ½ overflow**, Ä‘Ã³ lÃ  váº¥n Ä‘á» ngÃ y cÃ ng rÃµ khi:

* context window tÄƒng,
* dá»¯ liá»‡u Ä‘áº§u vÃ o ngÃ y cÃ ng phá»©c táº¡p,
* vÃ  khÃ´ng cÃ³ chiáº¿n lÆ°á»£c pruning/token budgeting tá»‘t thÃ¬ mÃ´ hÃ¬nh sáº½ bá»‹ "ngá»™p".

ğŸ›  Vai trÃ² cá»§a cÃ´ng cá»¥: `Tooling cho Context Design`

**Tooling nÃ o giÃºp thá»±c hiá»‡n Ä‘Æ°á»£c context engineering má»™t cÃ¡ch thá»±c tiá»…n?**

* **LangGraph, LangChain Expression Language (LCEL)**: Cho phÃ©p xÃ¢y dá»±ng context flow cÃ³ kiá»ƒm soÃ¡t (stateful logic)
* **LlamaIndex, Haystack**: Há»— trá»£ semantic chunking, context injection cÃ³ cáº¥u trÃºc
* **PromptLayer, Traceloop**: Tracking + debugging prompt/context behavior Ä‘á»ƒ há»c tá»« thá»±c táº¿
* **MemGPT, Agentic memory frameworks**: Khá»Ÿi Ä‘áº§u cho â€œLLM vá»›i trÃ­ nhá»› tháº­t sá»±â€ â€” ráº¥t quan trá»ng cho context dÃ i háº¡n.
* **tiktoken + Custom token routers**: Äá»ƒ phÃ¢n bá»• vÃ  kiá»ƒm soÃ¡t token budget theo má»¥c tiÃªu

> XÃ¢y dá»±ng má»™t há»‡ thá»‘ng cÃ³ kháº£ nÄƒng tÆ° duy báº±ng thiáº¿t káº¿ context thay vi "prompt thÃ´ng minh"
> 
> => AI sáº½ tá»± láº­p luáº­n chÃ­nh xÃ¡c, vÃ¬ nÃ³ Ä‘Ã£ â€œtháº¥y Ä‘Ãºng thá»©, theo Ä‘Ãºng cÃ¡ch, vÃ¬ Ä‘Ãºng lÃ½ doâ€

1. **Context lÃ  háº¡ táº§ng (infrastructure)**

* Context lÃ  **ná»n táº£ng dá»¯ liá»‡u mÃ  mÃ´ hÃ¬nh tiáº¿p cáº­n Ä‘Æ°á»£c**: hÆ°á»›ng dáº«n, vÃ­ dá»¥, dá»¯ liá»‡u truy xuáº¥t,...
* Náº¿u context **máº­p má», ráº£i rÃ¡c hoáº·c quÃ¡ dÃ i**, mÃ´ hÃ¬nh sáº½ "tháº¥y" sai hoáº·c thiáº¿u sÃ³t, tá»« Ä‘Ã³ **lÃ½ luáº­n sai**
* => **Náº¿u â€œinputâ€ lá»™n xá»™n, â€œoutputâ€ sáº½ vÃ´ nghÄ©a**

2. **Engineering lÃ  giao diá»‡n (interface)**

* **CÃ¡ch báº¡n cáº¥u trÃºc prompt** ~ kiá»ƒm soÃ¡t token, sá»­ dá»¥ng bá»™ nhá»›, phÃ¢n táº§ng thÃ´ng tin
* AI **hiá»ƒu rÃµ thÃ´ng tin nÃ o lÃ  quan trá»ng** => **táº­p trung Ä‘Ãºng má»¥c tiÃªu**.

3. **Reasoning lÃ  káº¿t quáº£ (outcome)**

* LÃ  kháº£ nÄƒng **láº­p luáº­n vÃ  Ä‘Æ°a ra pháº£n há»“i logic, chÃ­nh xÃ¡c**
* Náº¿u context Ä‘Æ°á»£c thiáº¿t káº¿ tá»‘t => AI cÃ³ nhiá»u báº±ng chá»©ng Ä‘á»ƒ trÃ¬nh bÃ y **lÃ½ do táº¡i sao pháº£i tráº£ lá»i nhÆ° váº­y**

âœ… **Danh sÃ¡ch kiá»ƒm tra ngá»¯ cáº£nh (1 phÃºt):**

* Nhiá»‡m vá»¥ + tiÃªu chÃ­ thÃ nh cÃ´ng
* Äá»‹nh nghÄ©a, schema
* VÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh, ká»ƒ cáº£ biÃªn
* Dá»¯ kiá»‡n cÃ³ nguá»“n
* Káº¿t quáº£ tá»« cÃ´ng cá»¥ liÃªn quan

ğŸ“ˆ **Máº«u ngá»¯ cáº£nh hiá»‡u quáº£:**

* Äá»‹nh nghÄ©a schema Ä‘áº§u vÃ o/ra (I/O), kiá»ƒu dá»¯ liá»‡u, giÃ¡ trá»‹ há»£p lá»‡
* Cung cáº¥p báº±ng chá»©ng trÆ°á»›c hÆ°á»›ng dáº«n (evidence-first)
* RÃ ng buá»™c rÃµ rÃ ng: MUST/NEVER + tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡
* Giá»›i háº¡n chunk + Æ°u tiÃªn dá»¯ liá»‡u gáº§n nháº¥t (90 ngÃ y)
* Chuáº©n hÃ³a thá»±c thá»ƒ (entity normalization)
* Gá»“m káº¿t quáº£ tá»« cÃ´ng cá»¥ náº¿u cáº§n (tool trace)

âŒ **Lá»—i phá»• biáº¿n khi thiáº¿t láº­p ngá»¯ cáº£nh:**

* Ngá»¯ cáº£nh quÃ¡ dÃ i, ná»™i dung chÃ­nh bá»‹ láº¥p
* Nguá»“n dá»¯ liá»‡u xung Ä‘á»™t hoáº·c trÃ¹ng láº·p
* Dá»¯ liá»‡u khÃ´ng sáº¯p xáº¿p, thiáº¿u liÃªn quan
* Thiáº¿u mÃ£ nguá»“n, khÃ´ng cÃ³ quy táº¯c phÃ¢n xá»­
* Trá»™n láº«n hÆ°á»›ng dáº«n vá»›i dá»¯ liá»‡u má»™t cÃ¡ch lá»™n xá»™n

#### ğŸ§  App demo:

* Cho phÃ©p cáº¥u hÃ¬nh:

  * `system prompt`
  * `user prompt`
  * `short-term memory`
  * `long-term memory`
  * `RAG documents`
  * `tools` (danh sÃ¡ch chá»©c nÄƒng giáº£ Ä‘á»‹nh)
  * `structured output format`
  * `guardrails` (validation/logic cÆ¡ báº£n)
* Káº¿t há»£p cÃ¡c thÃ nh pháº§n Ä‘á»ƒ táº¡o **context package**
* Cho phÃ©p xuáº¥t ra JSON cáº¥u hÃ¬nh context

#### âœ… 1. MÃ£ nguá»“n `context_builder_app.py`

```python
import streamlit as st
import json

st.set_page_config(page_title="ğŸ§  Context Engineering Builder", layout="wide")

st.title("ğŸ§  Context Engineering Builder")
st.markdown("Thiáº¿t káº¿ context Ä‘áº§y Ä‘á»§ cho há»‡ thá»‘ng LLM agent.")

# Tabs
tabs = st.tabs([
    "System Prompt", "User Prompt", "Memory", "RAG", "Tools", "Structured Output", "Guardrails", "Final Context"
])

# 1. SYSTEM PROMPT
with tabs[0]:
    st.header("ğŸ§¾ System Prompt")
    system_prompt = st.text_area("System Prompt", height=150, placeholder="Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh...")

# 2. USER PROMPT
with tabs[1]:
    st.header("ğŸ‘¤ User Prompt")
    user_prompt = st.text_area("User Prompt", height=150, placeholder="HÃ£y giÃºp tÃ´i lÃªn káº¿ hoáº¡ch há»c Python...")

# 3. MEMORY
with tabs[2]:
    st.subheader("ğŸ§  Short-term Memory (session-based)")
    stm = st.text_area("Short-term Memory", height=100, placeholder="CÃ¢u tráº£ lá»i gáº§n nháº¥t, ngá»¯ cáº£nh trÆ°á»›c Ä‘Ã³...")

    st.subheader("ğŸ“¦ Long-term Memory (persistent)")
    ltm = st.text_area("Long-term Memory", height=100, placeholder="ThÃ´ng tin ngÆ°á»i dÃ¹ng, lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c...")

# 4. RAG
with tabs[3]:
    st.header("ğŸ“š RAG Documents")
    rag_sources = st.text_area("List of document chunks or sources", placeholder="docs/faq.pdf, vector_db/index.json...")
    rag_embedding_model = st.selectbox("Embedding Model", ["OpenAI", "Cohere", "Local (e.g. Instructor)"])
    rag_top_k = st.slider("Top-K retrieved", 1, 10, 3)

# 5. TOOLS
with tabs[4]:
    st.header("ğŸ§° Tools")
    tools_list = st.multiselect("Select tools available to the model", [
        "Calculator", "Weather API", "Search", "File Reader", "Web Browser", "Code Interpreter"
    ])
    st.text("Báº¡n cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a toolchain riÃªng á»Ÿ backend.")

# 6. STRUCTURED OUTPUT
with tabs[5]:
    st.header("ğŸ“¤ Structured Output Format")
    output_format = st.text_area("JSON Schema hoáº·c template output", placeholder='{"task": "", "steps": [], "result": ""}')

# 7. GUARDRAILS
with tabs[6]:
    st.header("ğŸ›¡ï¸ Guardrails")
    toxicity_check = st.checkbox("âŒ Reject toxic output")
    safety_check = st.checkbox("âœ… Ensure tool use is validated")
    max_tokens = st.number_input("ğŸ”¢ Max Tokens Allowed", min_value=100, max_value=8000, value=2048)

# 8. FINAL CONTEXT COMPOSER
with tabs[7]:
    st.header("ğŸ§© Final Context Configuration")
    if st.button("ğŸ§¬ Generate Context JSON"):
        context_package = {
            "system_prompt": system_prompt,
            "user_prompt": user_prompt,
            "memory": {
                "short_term": stm,
                "long_term": ltm,
            },
            "rag": {
                "sources": rag_sources.split(","),
                "embedding_model": rag_embedding_model,
                "top_k": rag_top_k,
            },
            "tools": tools_list,
            "output_format": output_format,
            "guardrails": {
                "toxicity_filter": toxicity_check,
                "tool_validation": safety_check,
                "max_tokens": max_tokens,
            }
        }

        st.success("âœ… Context package generated!")
        st.code(json.dumps(context_package, indent=2), language="json")

        st.download_button("ğŸ“¥ Download Context JSON", data=json.dumps(context_package, indent=2), file_name="context_package.json")

```

<img width="1616" height="584" alt="image" src="https://github.com/user-attachments/assets/e4427e47-b822-4916-a029-10ebf1b5c7b4" />

#### Context engineering is no longer optional, it's a key pillar in building reliable AI agents

ğŸ“Œ INSTRUCTIONS - Set the stage clearly:

* Who: Give your AI a role ("Act as a senior developer")
* Why: Explain the bigger picture and business value
* What: Define success criteria and expected outcomes

ğŸ“Œ REQUIREMENTS - The "how-to" blueprint:

* Step-by-step processes
* Style guidelines and coding standards
* Performance constraints and security requirements
* Response formats (JSON, plain text, etc.)
* Examples of what TO do and what NOT to do
* Pro tip: Negative examples are gold for fixing common mistakes!

ğŸ“Œ KNOWLEDGE - Feed your AI the right information:

* External context: Industry knowledge, business models, market facts
* Task context: Workflows, documentation, structured data
* Think of it as giving your AI a comprehensive briefing

ğŸ“Œ MEMORY - Enable your AI to remember:

* Short-term: Chat history, current reasoning steps
* Long-term: User preferences, past experiences, learned procedures
* Note: Memory isn't just prompt textâ€”it's managed by your orchestration layer

ğŸ“Œ TOOLS - Describe available functions clearly:

* What each tool does
* How to use it properly
* Expected parameters and return values
* Remember: Tool descriptions are micro-prompts that guide AI reasoning!

ğŸ“Œ TOOL RESULTS - The feedback loop:

* AI requests tool execution in special format
* System responds with results
* AI continues with enriched context

### âœ… VÃ¬ sao context engineering quan trá»ng trong AI agent há»— trá»£ váº­n hÃ nh?

AI agent cho má»¥c Ä‘Ã­ch "operations" thÆ°á»ng cÃ³ cÃ¡c Ä‘áº·c Ä‘iá»ƒm sau:

| Äáº·c Ä‘iá»ƒm                                | Vai trÃ² context                                      |
| --------------------------------------- | ---------------------------------------------------- |
| âš™ï¸ LÃ m viá»‡c liÃªn tá»¥c nhiá»u vÃ²ng         | Giá»¯ Ä‘Æ°á»£c tráº¡ng thÃ¡i vÃ  tiáº¿n trÃ¬nh                    |
| ğŸ“‹ Pháº£i hiá»ƒu quy trÃ¬nh nghiá»‡p vá»¥        | ÄÆ°a vÃ o prompt quy trÃ¬nh, rule vÃ  má»¥c tiÃªu Ä‘Ãºng lÃºc  |
| â±ï¸ Pháº£n á»©ng linh hoáº¡t vá»›i thay Ä‘á»•i      | Context pháº£i cáº­p nháº­t sÃ¡t thá»±c táº¿ (real-time or RAG) |
| ğŸ§  Giao tiáº¿p vá»›i ngÆ°á»i & há»‡ thá»‘ng khÃ¡c  | Biáº¿t â€œai Ä‘ang nÃ³iâ€, Ä‘ang á»Ÿ Ä‘Ã¢u trong tiáº¿n trÃ¬nh      |
| âŒ Ráº¥t dá»… bá»‹ lá»—i khi thÃ´ng tin mÃ¢u thuáº«n | PhÃ¢n vÃ¹ng context ká»¹, trÃ¡nh clash & distraction      |

Náº¿u khÃ´ng quáº£n lÃ½ context tá»‘t â†’ Agent:

* **láº«n lá»™n task**
* **xá»­ lÃ½ sai quy trÃ¬nh**
* **há»i láº¡i thÃ´ng tin Ä‘Ã£ cÃ³**
* hoáº·c **táº¡o ra pháº£n há»“i rá»i ráº¡c, khÃ´ng theo ngá»¯ cáº£nh**

ğŸ”§ Nhá»¯ng ká»¹ thuáº­t context engineering cá»¥ thá»ƒ nÃªn dÃ¹ng trong agent váº­n hÃ nh

| Ká»¹ thuáº­t context                    | CÃ¡ch Ã¡p dá»¥ng                                                                                               |
| ----------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| **Context Windows**                 | Giá»¯ tráº¡ng thÃ¡i há»™i thoáº¡i gáº§n nháº¥t (task state) vÃ  thÃ´ng tin ngÆ°á»i dÃ¹ng trong cá»­a sá»• trÆ°á»£t (sliding window) |
| **Retrieval (RAG)**                 | Truy váº¥n SOP, policy, lá»‹ch lÃ m viá»‡c,â€¦ tá»« DB khi cáº§n chá»© khÃ´ng nhÃ©t háº¿t vÃ o prompt                          |
| **Context Tagging**                 | GÃ¡n nhÃ£n cho context (vÃ­ dá»¥: `#ticket-id-123`, `#onboarding-phase`) Ä‘á»ƒ dá»… truy xuáº¥t vÃ  lá»c                 |
| **Session Summary**                 | Sau má»—i tÃ¡c vá»¥ hoáº·c vÃ²ng há»™i thoáº¡i dÃ i, agent tá»± táº¡o báº£n tÃ³m táº¯t ná»™i bá»™ Ä‘á»ƒ sá»­ dá»¥ng trong phiÃªn sau         |
| **Role-based Context Partitioning** | Náº¿u agent tÆ°Æ¡ng tÃ¡c nhiá»u vai trÃ² (user, supervisor, IT, HR), thÃ¬ phÃ¢n vÃ¹ng riÃªng tá»«ng loáº¡i context        |
| **Context Decay / Pruning**         | XÃ³a bá»›t cÃ¡c thÃ´ng tin khÃ´ng cÃ²n liÃªn quan trong cÃ¡c phiÃªn má»›i                                              |

ğŸ§ª VÃ­ dá»¥ thá»±c táº¿: 
```
Agent há»— trá»£ váº­n hÃ nh trong cÃ´ng ty logistics
Giáº£ sá»­ AI agent giÃºp Ä‘á»™i Ä‘iá»u phá»‘i váº­n chuyá»ƒn:
```

* **Khi Ä‘iá»u phá»‘i xe hÃ ng**: agent pháº£i nhá»› cÃ¡c order gáº§n Ä‘Ã¢y, lá»‹ch xe cháº¡y, driver Ä‘ang lÃ m viá»‡c â†’ dÃ¹ng **context window + retrieval**
* **Khi cÃ³ sá»± cá»‘ (vÃ­ dá»¥: xe há»ng)**: cáº§n truy xuáº¥t **SOP vá» xá»­ lÃ½ sá»± cá»‘**, gá»i Ä‘Ãºng ngÆ°á»i â†’ dÃ¹ng **context tagging + role-aware retrieval**
* **Qua nhiá»u ca lÃ m viá»‡c**: context cÅ© khÃ´ng cÃ²n quan trá»ng â†’ dÃ¹ng **context pruning** Ä‘á»ƒ giáº£m Ä‘á»™ dÃ i
* **Cáº§n giá»¯ tiáº¿n trÃ¬nh nhiá»‡m vá»¥**: dÃ¹ng **session summary** Ä‘á»ƒ biáº¿t "task nÃ y Ä‘Ã£ lÃ m tá»›i Ä‘Ã¢u"

